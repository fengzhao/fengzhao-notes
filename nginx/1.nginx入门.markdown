# Nginx 介绍



Nginx ("engine x") 是一个高性能的 HTTP 和反向代理服务器，也是一个 IMAP/POP3/SMTP 代理服务器。

Nginx 是由 Igor Sysoev 为俄罗斯著名的 Rambler.ru 站点开发的，第一个公开版本 0.1.0 发布于 2004 年 10 月 4 日。

其将源代码以类 BSD 许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。

由于 Nginx 使用基于事件驱动的架构，能够并发处理百万级别的 TCP 连接，高度模块化的设计和自由的许可证使得扩展 Nginx 功能的第三方模块层出不穷。

因此其作为 Web 服务器被广泛应用到大流量的网站上，包括淘宝、腾讯、新浪、京东等访问量巨大的网站。

2015 年 6 月，Netcraft 收到的调查网站有 8 亿多家，主流 web 服务器市场份额（前四名）如下表：

| Web服务器         | 市场占有率 |
| :---------------- | :--------: |
| Apache            |   49.53%   |
| Nginx             |   13.52%   |
| Microsoft IIS     |   12.32%   |
| Google Web Server |   7.72%    |

其中在访问量最多的一万个网站中，Nginx 的占有率已超过 Apache。



Nginx 是一个高性能的 Web 服务器，从 2001 年发展至今，由于 Nginx 对硬件和操作系统内核特性的深度挖掘，使得在保持高并发的同时还能够保持高吞吐量。

Nginx 还采用了模块设计，有大量的第三方模块可以扩展 Nginx 的功能，因此 Nginx 的场景非常丰富，同时 Nginx 采用的是 BSD 许可证，赋予了 Nginx 最大的灵活性。

简单来说，Nginx 具有以下几个优点：


- 速度快
- 高并发，高性能
- 可扩展性好
- 高可靠，一年之中停机时间可能只有几秒
- 热部署，可以不重启升级
- 灵活性高，采用BSD 许可证



> BSD开源协议是一个给予使用者者很大自由的协议。
>
> 基本上使用者可以“为所欲为”,可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。



截止 2019 年 9 月份，Nginx 的市场份额已经达到了 33%，且还在持续增长，稳居市场头把交椅。



## 诞生背景

Nginx 出现的背景是由于互联网的快速普及导致数据量的快速增长，同时催生出了海量的连接。传统的 Apache 等服务器采用的是单进程模型，这意味着，每处理一个请求就会创建一个进程，这不但存在进程创建的开销。

而且进程之间相互切换产生的上下文开销也非常耗费 CPU 资源，导致这种传统的服务器在面对成千上万的并发连接时，性能非常低下，而这是快速发展的互联网所不能够忍受的。

在这种背景下，Nginx 采用的是进程池和 epoll 处理模型，这二者加起来使得 Nginx 的性能非常优异，一台 32 核的机器上可以支撑数千万的并发连接。



Nginx 有一个 master 进程和若干个 worker 进程。

master 进程是用来管理 worker 进程的，worker 进程负责处理具体的请求，worker 进程是 master 进程的子进程。

Nginx服务器的一个显著优势是能够同时处理大量并发请求。它结合多进程机制和异步机制对外提供服务，异步机制使用的是异步非阻塞方式

Nginx服务器启动后，可以产生一个主进程（master process）和多个工作进程（worker processes），其中可以在配置文件中指定产生的工作进程数量。

Nginx服务器的所有工作进程都用于接收和处理客户端的请求。这类似于Apache使用的改进的多进程机制，预先生成多个工作进程，等待处理客户端请求。

每个工作进程使用了异步非阻塞方式，可以处理多个客户端请。当某个工作进程接收到客户端的请求以后，调用IO进行处理，如果不能立即得到结果，就去处理其他的请求；

而客户端在此期间业务需等待响应，可以去处理其他的事情；当IO调用返回结果时，就会通知此工作进程；该进程的到通知，暂时挂起当前处理的事务，去响应客户端请求。

客户端请求数量增长、网络负载繁重时，Nginx服务器使用多进程机制能够保证不增长对系统资源的压力；同时使用异步非阻塞方式减少了工作进程在I/O调用上的阻塞延迟，保证了不降低对请求的处理能力。



## Nginx 及其周边

介绍完 Nginx 的背景，我们就该说说 Nginx 周边了。目前基于 Nginx 二次开发的软件主要如下：

- 官方 Nginx。包含开源版（nginx.org）和商业版（nginx.com）
- [freenginx](https://freenginx.org/en/)
- [Tengine](https://tengine.taobao.org/)，Tengine 是由淘宝网发起的 Web 服务器项目，目前已经开源。
- [OpenResty](https://openresty.org/cn/)，OpenResty 通过 Lua 对 Nginx 进行扩展，使得扩展 Nginx 模块变得异常轻松
- [kong](https://github.com/Kong/kong)，Kong Gateway (OSS) ，Kong是一个云原生，快速，可扩展和分布式微服务的开源API网关。
- [apisix](https://apisix.apache.org/zh/)，Apache APISIX 是一个动态、实时、高性能的云原生 API 网关，提供了负载均衡、动态上游、灰度发布、服务熔断、身份认证等功能。



最近，F5 前雇员、Nginx 项目主要贡献者`Maxim Dounin `发布了 Nginx 的分支 Freenginx。这个新项目是为了解决一个安全争议，并希望成为 Nginx 的可替代方案，由开发人员而不是企业实体负责运营。

Maxim Dounin，nginx开发的重要人物，宣布推出freenginx.org，这是一个新项目，旨在在没有企业控制的情况下继续开发nginx。此举是在F5收购nginx后，该公司做出了违背开源精神和`Dounin`之前与他们达成的协议的决定。

Dounin的举措非常重要，因为它代表了开发者主导项目和维护开源工作完整性对抗企业利益的立场。对于关心nginx在F5管理下的发展方向并有兴趣支持或贡献于以社区和开发者意见为重的替代方案的开发者和用户来说，这一公告尤为重要。





angie 是由原NGINX团队的核心成员创建的新型Web服务器和反向代理服务器（core 还是基于了nginx） 同时提供了以下周边扩展：

- 集成了proemtheus(内置)：自己开发了可以方便监控
- 提供了一个console：基于angie 的api 提供了console 管理



针对我们日常工作学习来说，选择官方开源版的 Nginx 或者 OpenResty 就可以了。

## Nginx 版本策略

------

在 Nginx 的[开源代码库](http://hg.nginx.org/nginx/branches)中，有两种分支，分别是 mainline 和 stable。

-  Mainline 相当于开发分支，更新比较活跃，包含引入一些新的功能或者bug修复，版本号的第二个数字如果是奇数，那就是 Mainline 版本，比如 1.17.0。
- Stable 分支很容易理解，就是相对稳定的版本，除非有重大Bug，否则在它的生命周期内不会更新，版本号的第二个数字如果是偶数，那就是 Mainline 版本，比如 1.16.0。

对于 NGINX 开源，“稳定”一词指的是功能和更新频率，而不是软件质量。稳定分支在其生命周期中从不接收新功能，通常只接收一两个更新，用于关键错误修复。

stable 版本代表功能多少和更新频率，和软件质量没有太大的关系（当然任何软件都会有Bug）。

在每年4月份会发布一次，它的生命周期是一年，在这段时间内，一般情况不会更新版本号（除非有重大Bug）。

https://www.cnblogs.com/91donkey/p/11639355.html



F5 前雇员、Nginx 项目主要贡献者发布了 Nginx 的分支 Freenginx。这个新项目是为了解决一个安全争议，并希望成为 Nginx 的可替代方案，由开发人员而不是企业实体负责运营

# 安装 Nginx 和 OpenResty

在 Linux 上，当然可以使用 yum、apt-get 等软件包管理工具来下载 Nginx，但是 Nginx 的很多模块并不是默认开启的，第三方模块很多也并不包含。

所以，如果想要开启内置的模块或编译第三方模块，还是需要编译 Nginx。



### 包管理器安装 nginx

------

```shell
# https://www.nginx.com/resources/wiki/start/topics/tutorials/install/

# 配置yum源：/etc/yum.repos.d/nginx.repo 

# CentOS
[nginx]
name=nginx repo
# 系统:CentOS7 架构:x86_64
baseurl=https://nginx.org/packages/centos/7/x86_64/

# 系统:CentOS8 架构:x86_64
# baseurl=https://nginx.org/packages/centos/7/x86_64/

# 系统:RHEL7 架构:x86_64
# baseurl=https://nginx.org/packages/rhel/7/x86_64/

# 系统:RHEL8 架构:x86_64
# baseurl=https://nginx.org/packages/rhel/7/x86_64/
gpgcheck=0
enabled=1


```



### 编译安装Nginx

在 <http://nginx.org/en/download.html> 里面可以直接下载 Nginx 源代码。包含以下目录：

```shell
# 添加运行nginx的用户
groupadd nginx
useradd -r -g nginx -s /bin/false nginx


# 安装依赖环境，确保编译正常
sudo yum install gcc gcc-c++ make automake autoconf libtool pcre* zlib openssl openssl-devel  pcre pcre-devel

sudo apt install zlib1g zlib1g-dev curl gnupg2 ca-certificates lsb-release ubuntu-keyring dirmngr software-properties-common apt-transport-https   gcc make libpcre3 libpcre3-dev   zlib1g-dev openssl libssl-dev 

# 在 http://nginx.org/en/download.html 里面下载 Nginx 源代码，永远下载最新的Stable release版本
wget http://nginx.org/download/nginx-1.28.0.tar.gz

# wget  https://github.com/openssl/openssl/releases/download/OpenSSL_1_1_1w/openssl-1.1.1w.tar.gz
# wget https://mirrors.ibiblio.org/openssl/source/openssl-1.1.1w.tar.gz

# https://www.cnblogs.com/chrdai/p/11306728.html
nginx-1.21.4
├── CHANGES 		# 每个版本提供的特性和 bugfix，changelog文件
├── CHANGES.ru 		# 俄罗斯版本的 CHANGES 文件
├── LICENSE			# 开源许可文件
├── Makefile        #    
├── README          # README说明文件
├── auto 			# 自动检测系统环境以及编译相关的脚本，辅助 configure 脚本执行的时候去判定nginx支持哪些模块，当前操作系统有什么样的特性可以供给nginx使用。
├── conf 			# 示例配置文件，方便运维配置，会把 conf 示例文件拷贝到安装目录
├── configure 		# 命令脚本，用来生成中间文件，执行编译前的一个必备动作
├── contrib 		# 提供了两个 pl 脚本和 vim 工具
├── html 			# 一个 500 错误的默认页面，另一个是默认的 index 页面
├── man 			# nginx 对 Linux 的帮助文件，man ./nginx.8
└── src 			# nginx 核心源代码
└── objs			# 备注：这是执行configure后产生的目录


src
├── core		 	# 基本的数据结构定义和核心代码	
├── event			# 
│   ├── modules
├── http
│   ├── modules
|	├── v2
|	├── v3
├── mail			
├── misc			
├── os
|	├── unix
|	├── win32
└── stream





# 配置 Vim 高亮, 如果 Vim 没有开启语法高亮的话，最好开启一下。如果没有 ~/.vim 文件夹就新建一个
cp -r contrib/vim/* ~/.vim
echo 'syntax on' > ~/.vimrc 

# 在 vim ~/.vim/ftdetect/nginx.vim 文件中指定，哪些文件，需要按照nginx的语法进行高亮显示
au BufRead,BufNewFile *.nginx set ft=nginx
au BufRead,BufNewFile */etc/nginx/* set ft=nginx
au BufRead,BufNewFile */usr/local/nginx/conf/* set ft=nginx
au BufRead,BufNewFile */usr/local/nginx/conf/* set ft=nginx




# Nginx是在 /usr/local/lib; /usr/pkg/lib; /opt/local/lib; 这三个路径下去查找OpenSSL library PATH
# 有时候因为nginx升级之后使用了高版本的Openssl，本地需要添加新模块重新编译nginx时候要升级openssl至指定版本。

# configure配置，configure之后，会生成Makefile文件，用于编译和构建nginx
# 
./configure   --user=nginx --group=nginx  --prefix=/usr/local/nginx/  --with-http_stub_status_module  --with-http_ssl_module


# 如果打算用源码的高版本openssl，那编译时候用./configure --with-http_ssl_module --with-openssl=/usr/local/openssl-1.0.2k

# 等号后面的绝对路径或者相对路径就是openssl的源码包tar.gz解压出来的目录，就是里面有目录啊，config二进制文件啊，README啦那些。

# https://blog.51cto.com/meiling/2165811
./configure   --user=nginx --group=nginx  --prefix=/usr/local/nginx/  --with-http_stub_status_module  --with-http_ssl_module --with-stream --with-http_v2_module --with-openssl=/usr/local/openssl/  


./configure --help # --help 命令可以查看配置脚本支持哪些参数

# 第一类配置参数

--prefix=PATH                      set installation prefix      						# 一般指定这个路径就可以了，其他文件会在 prefix 目录下建立相应的文件夹
--sbin-path=PATH                   set nginx binary pathname							#	
--modules-path=PATH                set modules path										# 
--conf-path=PATH                   set nginx.conf pathname								#
--error-log-path=PATH              set error log pathname								# 
--pid-path=PATH                    set nginx.pid pathname								#
--lock-path=PATH                   set nginx.lock pathname								#
--user=USER                        set non-privileged user for worker processes			#
--group=GROUP                      set non-privileged group for worker processes        #
--build=NAME                       set build name										# 在Nginx版本信息里加入自定义的字符串信息，比如公司名称，构建日期，源代码版本等。比如 --build="${USER} build at `date +%Y%m%d`"
--builddir=DIR                     set build directory									#
--add-module=PTAH																		# 指定第三方模块的源代码路径，可以出现N次。即表示添加多个模块。
--add-dynamic-module=PATH																# nginx1.9.11后新增动态模块


# 第二类配置参数
# 可以配置使用或不使用哪些模块，前缀通常是 with 和 with out。
## with开头的表示该模块默认是未开启的，可以使用--with开启。
## without开头的表示该模块默认是启用的，可以使用--without禁用。
## 第三方模块使用--add-module=PATH添加。如果支持动态加载，使用--add-dynamic-module=PATH添加。

--with-http_ssl_module             enable ngx_http_ssl_module
--with-http_v2_module              enable ngx_http_v2_module
--with-http_realip_module          enable ngx_http_realip_module
...
--without-http_charset_module      disable ngx_http_charset_module
--without-http_gzip_module         disable ngx_http_gzip_module
--without-http_ssi_module          disable ngx_http_ssi_module
...


# configure之后，就会生成objs目录。
root@server:/usr/local/src/nginx-1.25.1# ll objs/
total 92
drwxr-xr-x 3 root    root     4096 Apr 20 16:22 ./
drwxr-xr-x 9 tompson tompson  4096 Apr 20 16:22 ../
-rw-r--r-- 1 root    root    40425 Apr 20 16:22 Makefile
-rw-r--r-- 1 root    root    18290 Apr 20 16:22 autoconf.err
-rw-r--r-- 1 root    root     7457 Apr 20 16:22 ngx_auto_config.h
-rw-r--r-- 1 root    root      657 Apr 20 16:22 ngx_auto_headers.h
-rw-r--r-- 1 root    root     5856 Apr 20 16:22 ngx_modules.c
drwxr-xr-x 9 root    root     4096 Apr 20 16:22 src/
root@server:/usr/local/src/nginx-1.25.1#
root@server:/usr/local/src/nginx-1.25.1#




make && make install 



# nginx服务配置文件，使用systemd
# /lib/systemd/system/nginx.service
# https://www.nginx.com/resources/wiki/start/topics/examples/systemd/

[Unit]
Description=The NGINX HTTP and reverse proxy server
After=syslog.target network-online.target remote-fs.target nss-lookup.target
Wants=network-online.target
[Service]
Type=forking
PIDFile=/usr/local/nginx/logs/nginx.pid
ExecStartPre=/usr/local/nginx/sbin/nginx -t
ExecStart=/usr/local/nginx/sbin/nginx
ExecReload=/usr/local/nginx/sbin/nginx -s reload
ExecStop=/bin/kill -s QUIT $MAINPID
PrivateTmp=true
[Install]
WantedBy=multi-user.target
```



**配置 Vim**

如果 Vim 没有开启语法高亮的话，最好开启一下

```shell
cp -r contrib/vim/* ~/.vim
# mac 下需要在家目录下新建 .vimrc 文件并配置
syntax on
```



### 编译 Nginx

```shell
./configure --help # --help 命令可以查看配置脚本支持哪些参数


# 第一类配置参数

--prefix=PATH                      set installation prefix # 指定这个路径就可以了，其他文件会在 prefix 目录下建立相应的文件夹
--sbin-path=PATH                   set nginx binary pathname
--modules-path=PATH                set modules path
--conf-path=PATH                   set nginx.conf pathname
--error-log-path=PATH              set error log pathname
--pid-path=PATH                    set nginx.pid pathname
--lock-path=PATH                   set nginx.lock pathname
--user=USER                        set non-privileged user for worker processes
--group=GROUP                      set non-privileged group for worker processes
--build=NAME                       set build name
--builddir=DIR                     set build directory



# 第二类配置参数
# 可以配置使用或不使用哪些模块，前缀通常是 with 和 with out，需要加 with 参数的通常是不会被 Nginx 默认编译的，without 则是会移出编译。
## 比如说--with-http_ssl_module或者--with-http_v2_module，通常需要主动加--with的时候，意味着模块默认是不会编译进nginx的。


--with-http_ssl_module             enable ngx_http_ssl_module
--with-http_v2_module              enable ngx_http_v2_module
--with-http_realip_module          enable ngx_http_realip_module
...

## 比如说--without-http_charset_module意味着默认他会编译进nginx中，加了参数是把他移除默认的nginx的模块中。
--without-http_charset_module      disable ngx_http_charset_module
--without-http_gzip_module         disable ngx_http_gzip_module
--without-http_ssi_module          disable ngx_http_ssi_module
...





 # 1. 使用默认参数，进行 configure 指定编译安装目录
./configure --prefix=/usr/localnginx/
 # 编译完成后生成 objs 文件夹中间文件
➜   ls -al 
total 176
-rw-r--r--  1 mtdp  staff    40K  3  3 07:23 Makefile
-rw-r--r--  1 mtdp  staff    25K  3  3 07:23 autoconf.err
-rw-r--r--  1 mtdp  staff   5.4K  3  3 07:23 ngx_auto_config.h
-rw-r--r--  1 mtdp  staff   531B  3  3 07:23 ngx_auto_headers.h
-rw-r--r--  1 mtdp  staff   5.7K  3  3 07:23 ngx_modules.c # ngx_modules.c 决定了接下来的编译会生成哪些模块
drwxr-xr-x  9 mtdp  staff   288B  3  3 07:23 src
2. # 编译
make # 生成了大量的中间文件。如果是版本升级，就不能直接 makeinstall，需要将 obj 拷贝到安装目录。如果生成了动态模块，编译后也会放在 objs 目录下
3. # 安装
make install
➜  nginx ll # 安装完成后生成以下文件夹
total 0
drwxr-xr-x  17 mtdp  staff   544B  3  3 07:29 conf # 从 Nginx 源码目录拷贝的
drwxr-xr-x@  4 mtdp  staff   128B  3  3 07:29 html # 从 Nginx 源码目录拷贝的
drwxr-xr-x   2 mtdp  staff    64B  3  3 07:29 logs # 日志文件目录，包括 access log 和 error log
drwxr-xr-x   3 mtdp  staff    96B  3  3 07:29 sbin # Nginx 二进制文件目录
```



### Nginx 安装第三方模块

第三模块是对nginx 的功能扩展，第三方模块需要在编译安装nginx 的时候使用参数--add-module=PATH指定路径添加。

有的模块是由公司的开发人员针对业务需求定制开发的。

有的模块是开源爱好者开发好之后上传到github进行开源的模块，nginx支持第三方模块，需要重新编译源码才能支持。



**安装nginx安装第三方模块** 实际上是使用--add-module重新编译**安装**一次**nginx**，

不要 make install 而是直接把编译目录下 objs/**nginx **文件直接覆盖老的 **nginx **文件。如果你需要**安装**多个**nginx第三方模块**,你只需要多指定几个相应的--add-module即可



### 编译 OpenResty

OpenResty 的编译安装步骤与 Nginx 基本一致

在 <https://openresty.org/en/download.html> 中下载 OpenResty 的源代码，然后按照 Nginx 的编译步骤执行即可。

```bash
wget  https://openresty.org/download/openresty-1.21.4.1.tar.gz
```







# Nginx 配置文件





```nginx
events {
    worker_connections 1024;
}

http {
    #incloud mime.types;
    #default_type application/octet-stream;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
    #access_log logs/geek.access.log main;
    sendfile on;
    #tcp_nopush on;
    #keepalive_timeout 0;
    keepalive_timeout 65;

    gzip on;
    gzip_min_length 1;
    gzip_comp_level 2;
    gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png multipart/form-data;
    server {
        listen 8080;
        server_name 127.0.0.1;
        #charset koi8-r;
        access_log logs/geek.access.log main;
        location /lua {
            default_type text/html;
            content_by_lua '
			ngx.say("User-Agent: ", ngx.req.get_headers()["User-Agent"])
			';
			}
        }
        #error_page 404 /404.html;

    }
```





如上所示，是一个非典型的 Nginx 配置文件，Nginx 的配置文件语法遵循以下规则：

- 配置文件由指令与指令块构成
- 每条指令以 ; 结尾，指令与指令的参数之间以空格符号分割
- 指令块以 {} 将多条指令组织在一起

```
events { # 指令块
    worker_connections 1024; # 指令
}
```

- include 语句允许组合多个配置文件，以提升可维护性
- 使用 # 添加注释
- 使用 $ 符号添加变量
- 部分指令的参数支持正则表达式

## 配置参数

### 时间单位

- ms：毫秒
- s：秒
- m：分钟
- h：小时
- d：天
- M：月 = 30 天
- y：年 = 365 天

### 空间单位

- bytes
- k/K：kilobytes
- m/M：megabytes
- g/G：gigabytes

## HTTP 配置的指令块

- http：表示由 http 模块来处理请求
- upstream：表示上游服务器地址
- server：表示站点地址
- location：表示 URL

这些指令块在接下来都会遇到。





# Nginx 命令行

在刚刚编译完成的 Nginx 目录下，有一个 sbin 目录，就是用来存放 Nginx 的二进制文件的

```
➜  sbin ll
total 1712
-rwxr-xr-x  1 mtdp  staff   854K  3  3 07:29 nginx
```

Nginx 启动时，有一系列的命令行参数可以指定，下面分别介绍一下。

```bash
./nginx
-h/-? # 打开帮助
-c # 使用指定的配置文件，而不是默认的 conf 文件夹下的配置文件
-g # 指定配置命令，覆盖掉配置文件中的指令
-p # 指定运行目录
-s # 发送信号 stop 立刻停止服务；quit 优雅的停止服务；reload 重载配置文件；reopen 重新开始记录日志文件
-t/-T # 测试配置文件是否有语法错误
-v/-V # 打印 nginx 的版本信息、编译信息等
```



## 热部署

当配置文件发生变更时，需要重载配置文件：

```
nginx -s reload
```



# 升级/热升级

使用 Nginx 时，经常遇到添加新模块或升级Nginx版本。如何做到不停机升级部署？**Nginx热升级指服务不中断情况下用新的Nginx二进制文件替换老的Nginx二进制文件。**

热升级大致分为两步，按照新的要求编译好Nginx的二进制文件，通过信号，完成新老进程的平滑过渡，保证升级期间服务可用。



- 第一步：先查看原先编译的参数。`nginx -V` 可以查看编译时的参数。（`nginx -v`是查看版本）

  在新编译时，要将原有的模块参数也加上，否则原有的模块不会编译进去。

  

- 第二步：下载最新的nginx版本。并开始编译，编译过程和之前一致，只是增加了要添加模块的参数。

  > ./configure  --add-module=/xx/nginx-xx-moudule --with-compat --with-file-aio   
  >
  > 这里通过–add-module可以编译第三方的模块到Nginx。 这里只需要make编译，不要make install安装。编译完成后的nginx二进制文件在objs目录。一会要用到。
  >
  > 
  
- 第三步：备份和替换：先备份正在运行中的nginx二进制执行文件，将新编译的二进制nginx文件考到现在的目录并覆盖原先的nginx 

  > 先备份二进制执行文件  
  >
  > cd /usr/local/nginx/sbin/  && cp nginx nginx.bak 
  >
  > 将新编译的二进制nginx文件考到现在的目录并覆盖原先的nginx
  >
  >  cp -r nginx /usr/local/src/nginx/sbin/ -f

  

- 第四步：热升级。至此我们只是替换了二进制文件，但是现在服务中的Nginx进程还是由原来的nginx二进制文件启动的，所以请求还是走原有的逻辑。

  > 先通过ps -ef查看Nginx master进程id
  > 给nginx的master进程发送一个信号：USR2
  > kill -USR2 13195
  >
  > 向老nginx进程发送一个信号：WINCH 让其优雅关闭所有的worker进程
  > kill -WINCH 13195
  >
  > 此时所有的请求都会平滑过渡到新的worker进程。但是旧的master进程13195还在
  > 只是没有worker进程，如果要回退，只需要拉回旧的nginx拉回worker进程。如果运行一段时间没有问题，可以通过kill -QUIT 13159彻底关闭老进程
  >
  > 回滚：
  > kill -HUP 13195 #拉回原来的nginx进程 （kill -HUP 和 -SIGHUP 作用是一样的）
  > kill -QUIT 18034#关闭新起的master进程，该master进程会通知它下面的worker进程关闭

至此热升级完毕，其中最关键的是Nginx通过信号来协调新老进程的过渡。



Nginx是一个多进程应用，一般多进程通信可以采用共享内存、信号等通信方式。nginx的主进程和worker进程之间使用信号通信。开发者也会通过主动发送信号，控制nginx的行为，比如上面的热部署。

能够发送和处理信号的有Master进程、worker进程以及nginx命令行。通常我们不直接给worker进程发送信号，而是给master进程发送信号，希望通过master进程管理worker进程（master进程和worker进程之间也会互发信号进行通信）。

在信号名前加SIG也可以。比如 kill -HUP 和kill -SIGHUP一样。





# Nginx 配置指令

nginx.conf 文件是 nginx 中的核心文件，用于控制 nginx 的运行。



一个典型的 nginx 配置文件如下：

```nginx
main

http {
    upstream { … }
    split_clients {…}
    map {…}
    geo {…}
    server {
        if () {…}
        location {
            limit_except {…}
        }
        location {
            location {
            }
        }
    }
    server {
    }
}
```





## 指令块的嵌套



在 Nginx 配置文件中，指令块是可以嵌套分层的，例如上面的示例，http 块中可以包含多个 server 块，server 块中还会包含多个 location 块，每一个块中都有相应的指令。



而每一个指令都有 Context 上下文，也就是生效的环境，这在 Nginx 的官方文档中说的很清楚，例如下面的两条指令，Context 中都表明了各自可以生效的环境，access_log 指令可以在多个上下文中生效：



```nginx
Syntax:  access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];
         access_log off;
Default: access_log logs/access.log combined; 
Context: http, server, location, if in location, limit_except

Syntax:  log_format name [escape=default|json|none] string ...;
Default: log_format combined "..."; 
Context: http
```





## 指令的继承



既然 nginx 指令是可以嵌套分层的，而且指令可以存在于多个上下文环境。所以必然存在指令的继承。

例如下面的配置文件，这里面在 server 块和 location 块中都配置了 root 指令，Nginx 的继承规则如下：

- 子配置不存在时，直接使用父配置块的指令
- 子配置存在时，覆盖父配置块



```nginx
server {
    listen 8080;
    root /home/geek/nginx/html;
    access_log logs/geek.access.log main;
    location /test {
        root /home/geek/nginx/test;
        access_log logs/access.test.log main;
    }
    location /dlib {
        alias dlib/;
    }
    location / {
    }
}    
```



根据上面这两条规则，第一个 location 使用自己的 root 指令，后面两个 location 则使用 server 块的 root 指令。

这和编程语言中变量的作用域也是类似的，作用域更小的变量优先级往往更高，Nginx 的指令也是一样。



## 常用 nginx 指令

所有的指令，都可以在官网中https://nginx.org/en/docs/dirindex.html找到，一般搜索 nginx directives 也可以找到。



### **Main**

Nginx的主配置文件是 nginx.conf，这个配置文件一共由三部分组成，分别为**全局块、events块和http块**。在http块中，又包含http全局块、多个server块。每个server块中，可以包含server全局块和多个location块。

在同一配置块中嵌套的配置块，各个之间不存在次序关系。



```nginx
# 指定运行nginx服务的用户和用户组，只能在全局块配置，一般设置成nginx或者nobody用户
user nginx;
# 指定工作线程数，可以制定具体的进程数，默认是auto，等于CPU核数，这个指令只能在全局块配置
worker_processes number | auto；


# 指定pid文件存放的路径，这个指令只能在全局块配置
# pid logs/nginx.pid;

# 指定错误日志的路径和日志级别，此指令可以在全局块、http块、server块以及location块中配置。其中debug级别的日志需要编译时使用--with-debug开启debug开关
# error_log [path] [debug | info | notice | warn | error | crit | alert | emerg] 
# error_log  logs/error.log  notice;
# error_log  logs/error.log  info;
```



#### 进程管理配置

```nginx
worker_process number |auto ;
master_process on|off;
daemon on|off;
worker_cpu_affinity auto [cpumask] ;
woring_directory path;
worker_shutdown_timeout time;
```



#### 事件机制





### http 块

Nginx近 80% 的功能都是提供 HTTP 服务，所以 HTTP 的配置也是最复杂的。

http 是最顶层的指令之一了，它必须直接在 main 中使用。

```nginx
##########################################################MAIN############################################################## 
# MAIN块的指令是全局参数，全局生效，对整体产生影响。

user nginx;                        # 指定运行nginx进程的用户，Default: nobody
worker_processes  auto;            # 工作进程数，默认是auto，等于CPU核数
error_log  logs/error.log;         # 错误日志路径
pid        logs/nginx.pid;         # pid路径 
worker_rlimit_nofile 8192;         # 最大打开文件句柄数

events {
  worker_connections  4096;       ## 单个工作进程可以允许同时建立外部连接的数量。Default: 1024
}
# worker_processes与worker_connections 设置好合适大小，可以提示nginx处理性能，非常重要
##########################################################MAIN############################################################## 

http {
    
  include    conf/mime.types;                    
  include    /etc/nginx/proxy.conf;
  include    /etc/nginx/fastcgi.conf;
  index    index.html index.htm index.php;

  default_type application/octet-stream;
    
  server { 
    # php/fastcgi
    listen       80;
    server_name  domain1.com www.domain1.com;
    access_log   logs/domain1.access.log  main;
    root         html;

    location ~ \.php$ {
      fastcgi_pass   127.0.0.1:1025;
    }
  }  
    
    server {
       ...
    }
    
}    

```



### server 块

server 是 nginx 中最重要的指令了，它必须被包含在 http 块中使用。一个http块中可以有多个 server块，每个 server 就定义了一个虚拟主机，可以让 nginx 支持多个虚拟主机。

虚拟主机是一种特殊的软硬件技术，它可以将网络上的每一台计算机分成多个虚拟主机，每个虚拟主机可以独立对外提供 www 服务，这样就可以实现一台主机对外提供多个 web 服务，每个虚拟主机之间是独立的，互不影响的。

通俗说，一个虚拟主机就是一个网站。

```
http{
	server {
		listen   		80;
		server_name  	www.domain.com;
	}
}
```

### server_name 指令

server_name 指令是用来配置究竟是哪个 server 块来处理我们的请求的。它必须在 server 块中使用。

- server_name 指令后可以跟多个域名，第一个是主域名，多个域名之间空格分隔。
- 泛域名：仅支持在最前或最后加 * 通配符匹配任意字符串，例如：`*.demo.com` 和 `test.nginx.*`
- 正则表达式匹配：`server_name www.taohui.tech ~^www\d+\.taohui\.tech$;`

nginx 是如何处理一个请求的，假设有这样一个配置文件，配置了三个域名。

```nginx
server {
    listen      80;
    server_name example.org www.example.org; 
    ...
}

server {
    listen      80;
    server_name example.net www.example.net;
    ...
}

server {
    listen      80;
    server_name example.com www.example.com;
    ...
}
```

当 nginx 接收到 http 请求时，先从请求头提取到 HOST 头部字段，然后跟 server_name 匹配来确认是哪个server块来处理请求。

如果都不匹配，那么就用这个端口号的 `default_server` 来处理。

在这个例子中，就是第一个来处理。——这是nginx的标准做法。也可以在端口号后面加上一个 `default_server` 来显示指定这个行为。

```nginx
server {
    listen      80 default_server;
    server_name example.net www.example.net;
    ...
}
```

**注意在这个配置中，default_server只是跟在端口后面，并没有配置在域名上面。 **



对于请求头中没有HOST头部的请求，如果要禁止访问，可以设置如下配置：没有host头部的请求就会被这个server匹配上，并返回非标准的444状态码关闭连接。

```nginx
# 
server {
    listen      80 default_server;
    server_name "";
    return      444;
}
```



server_name 指令是用来配置究竟是哪个 server 来处理我们的请求的。有时候，一个 `server_name` 中可能会有多个域名，这时候是如何选择的呢？

1. server_name 指令后可以跟多个域名，第一个是主域名，多个域名之间空格分隔。
2. 泛域名：仅支持在最前或最后加 *，例如：`server_name *.taohui.tech`
3. 正则表达式匹配：`server_name www.taohui.tech ~^www\d+\.taohui\.tech$;`

当 server_name 指令后有多个域名时，会有一个 `server_name_in_redirect` 的配置，这个配置默认关闭，它使用来控制域名重定向的，也就是这个配置开启之后，请求过来会重定向到主域名访问。

```nginx
Syntax  server_name_in_redirect on | off;
Default server_name_in_redirect off; 
Context http, server, location
```





### listen 指令

listen 指令在 server 块中生效，用来配置监听哪些网络接口地址，哪些端口，由这些端口来处理请求。listen 指令的配置语法如下：

```nginx
Syntax:	listen address[:port] [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
listen port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
listen unix:path [default_server] [ssl] [http2 | spdy] [proxy_protocol] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];

# 默认值
Default:	 listen *:80 | *:8000;

# 只能出现在server块中
Context:	server



# 常见的litsen配置语法

listen 443 ssl http2; # 监听443，开启https，开启http2协议
# 对于nginx1.25之后，需要用单独的指令"http2 on"这样来配置，不支持在litsen后面这样写了。
# 参见：http://nginx.org/en/docs/http/ngx_http_v2_module.html


listen 127.0.0.1:8080;
listen 8080;
listen *:8080;
listen *:8080;



```



### root指令

root 指令指定了 Nginx 查找文件的根目录，适用与`server` 和 `location`。可以指定多个，如果 `locaiton` 中没有指定，会往其外层的 `server` 或 `http` 中寻找继承。



```nginx
location /request_path/image/ {
	root /local_path/image/;
}
```



这样配置的结果就是当客户端请求 `/request_path/image/cat.png` 时，`Nginx` 把请求映射为 `/local_path/image/request_path/image/cat.png`



```nginx
location /static {
	root /var/www/html/static;
}

# 对于这个配置
# 我们访问http://127.0.0.1/static/stc.jpg，发现并不能显示图片，通过查看`error.log`发现我们最后访问的地址是`/var/www/html/static/static/stc.jpg`。所以 root 中配置的路径要去掉最后的`static`。
```

**其实就是将访问的地址进行拼接了上去**



```nginx
location /static {
	root /var/www/html;
}

location /static/ {
	root /var/www/html;
}


# 如果在location最后多加一个斜杠/，这样一来最后拼接后变成了这样/var/www/html/static//stc.jpg，这样并不会影响我们访问资源，因为在nginx中，多个斜杠/和一个斜杠/是等价的。


# 配置 location /static 可以匹配 /static/content.js 这种请求，也可以匹配 /static11/ 等等，只要以 wandou 开头的目录都可以匹配到。
# 配置 location /wandou/ 必须精确匹配 /wandou/ 这个目录的请求,








```



**有时候访问的地址要求后面以 / 结尾，如果用户忘记输入 /，Nginx 就会自动加上 /**

```nginx
server {
	listen	80;
	server_name localhost;
	location / {
		root html;
		index index.html;
	}
}
```

要想访问上述资源，很简单，只需要通过  http://192.168.200.133  直接就能访问，地址后面不需要加 /



````
server {
	listen	80;
	server_name localhost;
	location /frx {
		root html;
		index index.html;
	}
}
````



这个时候，要想访问上述资源，按照上述的访问方式，我们可以通过 http://192.168.200.133/frx/ 来访问，但是如果地址后面不加斜杠，如 http://192.168.200.133/frx，页面就会出问题。

如果不加斜杠，Nginx 服务器内部会自动做一个 301 的重定向，重定向的地址会有一个指令叫 `server_name_in_redirect` 来决定重定向的地址：

- 如果该指令为 on重定向的地址为：http://server_name/目录名/

- 如果该指令为 off重定向的地址为：http://原URL中的域名/目录名/


所以就拿刚才的地址来说，访问 http://192.168.200.133/frx 如果不加斜杠，那么按照上述规则：

- 如果指令 server_name_in_redirect 为 on，则 301 重定向地址变为 http://localhost/frx/，IP 发生改变，地址出现了问题
- 如果指令 server_name_in_redirect 为 off，则 301 重定向地址变为 http://192.168.200.133/frx/。这个符合我们的期望



注意 server_name_in_redirect 指令在 Nginx 的 0.8.48 版本之前默认都是 on，之后改成了 off，所以现在我们这个版本不需要考虑这个问题，但是如果是 0.8.48 以前的版本并且 server_name_in_redirect 设置为 on，我们如何通过 Rewrite 来解决这个问题？


```nginx

```

```nginx
location static/ {
	root /var/www/html;
}
```





### location指令

nginx官方文档给出location语法如下：

```nginx
location [=|~|~*|^~] uri {
	...
}
```





| 标识符 | 描述                                                         |
| ------ | ------------------------------------------------------------ |
| =      | **精确匹配**；用于标准uri前，要求请求字符串和uri严格匹配。如果匹配成功，就停止匹配，立即执行该location里面的请求。 |
| ~      | **正则匹配**；用于正则uri前，表示uri里面包含正则，并且区分大小写。 |
| ~*     | **正则匹配**；用于正则uri前，表示uri里面包含正则，不区分大小写。 |
| ^~     | **非正则匹配**；用于标准uri前，nginx服务器匹配到前缀最多的uri后就结束，该模式匹配成功后，不会使用正则匹配。 |
| 无     | **普通匹配（最长字符匹配）**；与location顺序无关，是按照匹配的长短来取匹配结果。若完全匹配，就停止匹配。 |



```nginx
location = / {  
   //精确匹配/ ，主机名后面不能带任何字符串
    echo "规则A";
}

location = /login {
  //精确匹配 /login 开头的地址，匹配符合以后，不在继续往下搜索 
    echo "规则B";
}

location ^~ /blog/ { 
  //非正则匹配，匹配/blog/后，停止往下搜索正则，采用这一条
  echo "规则C";
}
 
location ~  \.(gif|jpg|png|js|css)$ {
    //区分大小写的正则匹配  若匹配成功，停止往下搜索正则，采用这一条
    echo "规则D";
}

location ~* \.png$ {  
   //区分大小写的正则匹配 ，停止往下搜索正则，采用这一条
    echo "规则E";
}
 
location / {
  //因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求
  //如果没任何规则匹配上，就采用这条规则
    echo "规则F";
}
 
location /blog/detail { 
  //最长字符串匹配，若完全匹配成功，就不在继续匹配，否则还会进行正则匹配
  echo "规则G";
}
 
location /images {  
    //最长字符串匹配，同上 
    echo "规则Y";
}
 
location ^~ /static/files {  
    //非正则匹配，若匹配成功，就不在继续匹配
    echo "规则X";
```



- 当访问根路径/的时候，比如https://www.fengzhao.me/ ，会匹配规则A。

- 当访问http://www.fengzhao.me/login ，会匹配规则B。

- 当访问http://www.fengzhao.me/login.html ，会匹配规则F。

- 当访问http://www.fengzhao.me/blog/detail/3.html ，会匹配规则C。

分析思路，首先看看，“**精确匹配**”是否可以匹配成功，显示不可以；然后，看看是否可以“**普通匹配**”是否可以完全匹配，显示也没有；接着在看看非正则匹配，是否可以匹配成功，发现同规则C匹配上了，所以采用了规则C。





### internal 指令

在Nginx中，internal location是一种特殊的URL，它只能从Nginx内部访问，不能从客户端浏览器直接访问。

这种规则通常用于内部的微服务通信，并且可以减少对外部的负载以及提高安全性。



Nginx 的 [internal 指令](http://nginx.org/en/docs/http/ngx_http_core_module.html#internal)可以用来限制 Web 公共目录下的图片等资源文件被任意用户直接访问。

一个明显的使用场景是，对于用户上传的认证图片，属于个人隐私资源，不应该让所有用户都能访问得到，通常只能由管理员审核时查看。

假定需要限制访问的图片的 URL 路径是 /images/auth-pictures/，Nginx 进行如下配置：

```nginx
location ^~ /images/auth-pictures/ {
  internal;
}
```

重启 Nginx，直接访问 /images/auth-pictures/ 下的图片，会返回 404



```nginx
server {
  listen  80;
  server_name your.host;

  access_log off;

  location /api {
    proxy_pass http://localhost:3000;
  }

  location /internal {
    internal;
    proxy_pass http://localhost:3000;
  }
}
```





# Nginx模块

打开[官方文档](https://nginx.org/en/docs/)中，可以看到Nginx的语法和模块被分为`Introduction`,`How-To`,`Development`,`Modules reference` 四块。



Nginx 的模块系统主要分为“核心功能模块”和“动态模块”，其中动态模块又分为官方模块和三方模块。某种意义上来看，Nginx 的模块算是一种 AOP 思想的应用实践。





## 内部模块

Nginx 能保持高度曝光发展到今天，除了因为有大量三方模块外，这些拥有稳定质量的内部模块同样功不可没。时至今日，[这些模块](https://github.com/nginx/nginx/tree/master/src)还在保持着比较高的频率进行小步迭代，不断进行优化。它们实际如下：

- 负责内部通用数据类型、数据对象、内存管理、文件管理、哈希校验、网络通信、锁、网络连接、日志管理、计时器的“核心模块”；

- 负责在不同操作系统，使用不同的事件方案最优解的“事件模块”；
- 负责门面担当、提供高性能 Web 服务的 “HTTP 模块”；
- 提供通用 TCP 代理服务功能的“流模块”；
- 负责邮件服务代理功能的“邮件功能”；以及解决系统差异的“OS模块”。



这些模块是 Nginx 的一部分，在一次次编译后，伴随着二进制软件包被分发至千家万户，跨越国界、跨越操作系统，大到绵延数个国家的跨国商业公司、小到你家里的路由器、甚至是电梯里的工控机中都能看到它的身影。

如果 Nginx 缺少了以上任何一个模块、或者模块和 Nginx 主文件版本不一致，软件都将停止工作、或者无法提供高质量的服务能力，可以被称之“亲儿子模块”，都属于标准的静态模块。

随着 Nginx 版本迭代更新，如果这些模块没有跟上版本迭代而和 Nginx 一起重新构建编译，那么原本的功能便会失效或者引起软件故障。漫长的编译过程，对于模块维护者，尤其是为爱发电的开源作者们来说，无疑是一个不必要的负担。



## 外部模块









## 常见官方模块



### ngx_http_core_module

提供http协议的支持。平常配置的http段、server虚拟主机段、location段等。都是此模块的中的一些配置语法。

### ngx_http_gzip_module

使用`gzip`方法压缩，有助于将传输数据的大小减少为一半甚至更多。提供请求返回速度。

**什么是网站gzip压缩**

正常浏览器通过URI访问服务时，下载的资源都是源文件大小。开启gzip压缩时，服务器在响应之前，对资源进行gzip压缩，并追加Content-Encoding: gzip响应头。

浏览器接收响应之后，会检查Content-Encoding响应头，若是gzip，则先对响应进行gzip解压，然后交给浏览器，进行解析及渲染等一系列操作。



**网站gzip压缩的优点**

网站开启gzip以后，会将输出到用户浏览器的数据进行压缩处理，这样会减小通过网络传输的数据量，达到提升网页加载速度、提升用户浏览体验。

网站开启gzip并非全是优点，gzip压缩算法属于依赖CPU型操作，在服务器端大量的资源进行gzip压缩，会占用服务器CPU和磁盘资源。但对于目前CPU性能来说，其影响微乎其微。

使用SSL/TSL协议时，压缩的响应可能会受到BREACH攻击。



### ngx_http_proxy_module

该模块允许将请求转发到其他服务器，实现代理服务器的功能。常见于实现反向代理服务器。





当`nginx`被用来反向代理上游服务器(比如一个`PHP-fpm`实例)时， 隐藏在上游响应中发送的某些报头(比如PHP运行的版本)是有益的。

可以使用`proxy_hide_header`(或Lua模块)来隐藏/删除上游服务器返回到你的`nginx`反向代理(并最终返回到客户端)的头文件。

> 使用方式：代理`http`服务的`location`块添加`include /etc/nginx/conf/conf.d/hide-headers.rule;`



````nginx configuration 
```
upstream ddd-server { 
	server 11.11.11.11:80; 
	server 11.11.11.12:80; 
} 

server { 
	listen 8081; 
	location /ddd  { 
		include /etc/nginx/conf/conf.d/hide-headers.rule; 
		proxy_pass http://ddd-server; 
		} 
}

# /etc/nginx/conf/conf.d/hide-headers.rule
proxy_hide_header X-Application-Context;
proxy_hide_header Access-Control-Allow-Origin;
proxy_hide_header X-Powered-By;
proxy_hide_header X-AspNetMvc-Version;
proxy_hide_header X-Drupal-Cache;
proxy_hide_header X-Powered-By;
proxy_hide_header Server;
proxy_hide_header X-AspNet-Version;
proxy_hide_header X-Drupal-Dynamic-Cache;
proxy_hide_header X-Generator;
proxy_hide_header X-Runtime;
proxy_hide_header X-Rack-Cache;
````





### ngx_http_upstream_module 



### ngx_http_gzip_module



### ngx_http_map_module 

map 指令是由 `ngx_http_map_module` 模块提供的，默认情况下nginx 会安装该模块。

map 的主要作用是`创建自定义变量`，通过使用 nginx 的`内置变量`,去`匹配`某些特定规则;

```nginx
# $args 是nginx内置变量，就是获取的请求 url 的参数。

# map定义两个变量的映射关系：当 $args 的值等于 debug 的时候，$foo 变量的值就是 1，否则 $foo 的值就为 0.

map $args $foo {
    	default     0;
    	debug       1;
    }

server {
        listen 8080;

        location /test {
        	# 将变量$foo的值赋给变量$orig_foo
            set $orig_foo $foo;
        
        	# 强行修改 $args 的值为 debug
            set $args debug;

            echo "original foo: $orig_foo";
            echo "foo: $foo";
        }
    }
curl 'http://localhost:8080/test'

# 第一行输出"original foo: 0"
# 这个请求并没有提供 URL 参数串，$args 最初就是空值，根据map规则，$foo则应当为0

# 第二行输出"foo: 0"
# 在强行改写 $args 变量的值为字符串 debug 之后，$foo 仍然是 0，显然不符合map规则。

# 原因是$foo在第一次读取时，根据映射规则计算出的值被缓存住了



```





### ngx_http_sub_module

ngx_http_sub_module模块是一个过滤器，它修改网站响应内容中的字符串，比如你想把响应内容中的`123`全部替换成`321`，这个模块已经内置在nginx中，但是默认未安装，需要安装需要加上配置参数：**--with-http_sub_module**

在reponse的时候，对http的内容进行替换。比如说在开发中有多台的主机，但是在返回的时候需要对各台主机的内容来进行替换，那么就需要用到这个。

官方文档地址http://nginx.org/en/docs/http/ngx_http_sub_module.html





## 动态模块

原生 Nginx 增加、修改一个第三方模块，需要重新编译源代码，所有的模块都是用静态链接的形式组织起来的。

Tengine 有一个增强的功能，即动态模块加载 DSO(Dynamic Shared Objects)，可以实现运行时动态加载模块，而不用每次都要重新编译Tengine。

在 2016 年农历春节期间，Nginx 官方发布了最新版本 Nginx-1.9.11，也增加了该功能。

从使用的角度上来说，是增加了一个指令 [load_modules](http://nginx.org/en/docs/ngx_core_module.html#load_module) 指令，来加载编译好 so 形式的动态模块。







```
具体使用的时候,主要为6个步骤;

　　(1):首先,要在nginx的源代码中加入configure 加入动态模块的时候必须指明这个模块是使用动态模块的的方式编译进nginx中;这里有一个潜台词,不是所有的nginx模块都可以以动态模块的方式加入到nginx中;只有一些模块才可以以动态模块的方式加入;

　　(2):开始执行make,编译出binary;

　　(3):到第三步的时候,也就是说我们开始启动nginx了;启动nginx的时候尼我们去读ngx_module里的数组;

　　(4):读到模块数组中尼,我们发现了使用了一个动态模块,接下来我们会看到一个nginx的conf中加入的一个配置项,这个配置项叫load_module配置;指明了这个　　　  动态模块所在的路径,

　　(5):那么接下来我们就可以在nginx的进程中打开这个动态库加入模块数组,

　　(6):最后再进行一个初始化的过程(基于模块数组进程初始化);
```







NGINX 1.9.11开始增加加载动态模块支持，从此不再需要替换nginx文件即可增加第三方扩展。目前官方只有几个模块支持动态加载，第三方模块需要升级支持才可编译成模块。

https://www.cnblogs.com/binghe001/p/13303716.html





# Nginx重写和重定向

一直对nginx的重写和重定向都是只有一个模糊的认识，只是知道在nginx里return、rewrite、proxy_pass能实现我想要的转发。



每次查阅资料时，各种关键词充斥在眼前：“重写”、“重定向”、“隐式转发”、“内部重定向”......一直没有区分清楚他们之前的区别或联系。



随之产生几个问题，想要花点时间搞清楚它们：

- 重写和重定向的区别是什么？
- nginx中“重写”、“重定向”、“隐式转发”、“内部重定向”......这些名词的关系是什么？在nginx是否都由一个独立的模块、关键字来实现这些的？
- nginx中`return`、`rewrite`、`proxy_pass`它们的区别是什么？对于重写和重定向，它们是否各自实现不同的功能？



首先重写和重定向的最终目的是一样的

假如你通过浏览器和固定的链接经常访问一张“好看的图片”，有一天图片的维护者将它移动了位置（换了目录、或者干脆移动到其他域名），那意味着你访问不到这张图片了？

为了避免这样的情况给用户带来的困扰，可以使用**重写**或者**重定向**，**将你的请求转向新的位置**（这张图片新的位置），对你来说还是用老的固定的链接访问到了你喜欢的图片。



**重定向**：重定向是用户请求服务端后，服务端向客户端返回HTTP 301、302（303、304、307、308）响应，告诉客户端需要去尝试另一个URL。

意味着客户端知道使用另一个URL并去访问。（客户端发起两次请求）

重定向的请求路径如下：

- request1（来自客户端）：访问“好看的图片” 
- response1（来自服务端）：你要访问的图片不在这了，你需要去访问“好看的图片新的位置”
- request2（来自客户端）：访问“好看的图片新的位置”
- response2（来自服务端）：拿去吧，你要的“好看的图片新的位置”对应的图片



**重写**：重写发生在服务器上。服务器内部将一个URL转到另一个URL，然后返回给客户端。

客户端并不知道自己的请求被转过一次，浏览器中的URL也始终是一开始访问的那个。（客户端发起一次请求）

重写的请求路径如下：

- request1（来自客户端）：访问“好看的图片”
- 重写（服务端处理）：将“好看的图片”改到“好看的图片新的位置”，获取到图片

- response1（来自服务端）：拿去吧，你要的“好看的图片”对应的图片



从浏览器的反馈来看。重写-客户端只会发送一次请求；重定向-客户端会发送两次请求。





重写和重定向在上面已经解释过了。关于其他名词的解释，在网上搜罗了一下：

- 隐式转发/隐形转发/隐藏式跳转：将请求跳转到另一个网站的页面，并且浏览器中URL保持不变。
- 显示转发：将请求跳转到另一个网站的页面，浏览器中URL会发生改变。
- 内部重定向：内部重定向（重写）发生在server端内部，client端不知情，浏览器上URL不会改变。
- 外部重定向：外部重定向是server端通知client端需要访问新的URL，client端进行第二次访问。浏览器中URL也变成新的URL。

思来想去，似乎就是对重写和重定向取了好多名字。所以个人理解的总结：

重写     = 隐式转发 = 内部重定向
重定向 = 显示转发 = 外部重定向





# Nginx限流配置



流量限制(rate-limiting)，是 Nginx 中一个非常实用，却经常被错误理解和错误配置的功能。我们可以用来限制用户在给定时间内 HTTP 请求的数量。

请求，可以是一个简单网站首页的 GET 请求，也可以是登录表单的 POST 请求。



流量限制可以用作安全目的，比如可以减慢暴力密码破解的速率。

通过将传入请求的速率限制为真实用户的典型值，并标识目标URL地址(通过日志)，还可以用来抵御 DDOS 攻击。

更常见的情况，该功能被用来保护上游应用服务器不被同时太多用户请求所压垮。





- [ngx_http_limit_req_module](https://nginx.org/en/docs/http/ngx_http_limit_req_module.html)

- [ngx_http_limit_conn_module](https://nginx.org/en/docs/http/ngx_http_limit_conn_module.html)



ngx_http_limit_conn_module 对于一些服务器流量异常、负载过大，甚至是大流量的恶意攻击访问等，进行并发数的限制；

该模块可以根据定义的键来限制每个键值的连接数，只有那些正在被处理的请求（这些请求的头信息已被完全读入）所在的连接才会被计数。



该模块提供了两个配置参数，limit_conn_zone 和 limit_conn 。

其中 limit_conn_zone 只能配置在 http{} 段，而 limit_conn 则可以配置于http{}，server{}，location{} 区段中。



https://www.cnblogs.com/biglittleant/p/8979915.html





注意事项：



事务都具有两面性的。ngx_http_limit_conn_module 模块虽说可以解决当前面临的并发问题，但是会引入另外一些问题的。

如前端如果有做LVS或反代，而我们后端启用了该模块功能，那不是非常多503错误了？这样的话，可以在前端启用该模块，要么就是设置白名单。





# Nginx热升级

 热升级要升级的部分一般是要**添加新的模块**或者**升级Nginx版本**。前者如果是编译第三方模块需要先准备好模块源代码，对于后者需要先下载最近Nginx源码。

热升级是指在**不停止服务（不影响客户端访问）**的情况下更换 Nginx 的binary文件。

这种热升级得益于nginx的**多进程架构**设计，能够在老的nginx主进程不退出的情况下以子进程的方式启动新的master进程和新的woker进程，让新的master进程重新监听端口和接收请求。

新的master进程稳定之后，通过发送信号的方式通知老master进程退出。完成整个热升级。





热升级会经历以下几个步骤：

**第一步**是把旧的 Nginx binary 文件替换为新的，之所以说只替换 binary 文件是因为大部分场景下，我们新编译的 nginx 文件所指定的相应的配置选项，比如说配置文件的目录在哪里？log 的所在目录在哪里？

必须保持和老的 Nginx 是一致的，否则的话没有办法复用 nginx.conf 文件，如果我们仅仅替换 binary 文件，请注意要备份，另外在新版本的 Linux 中，会要求在覆盖一个正在使用的文件时需要用 cp -f 才能够替换。

```bash
# 第一步：先查看原先编译的参数。nginx -V可以查看编译时的参数（-v是查看版本）。在新编译时，要将原有的模块参数也加上，否则原有的模块不会编译进去。

# 第二步：开始编译，编译过程和前面的一致，只是增加了要添加模块的参数。
```



**第二步**向现有老的 Master (Old) 进程发生 USR2 信号，之后 Master (Old) 进程会将修改 pid 文件名，添加 后缀 .oldbin。这一步是在为新的 Master 进程让路，虽然 Master、Worker 进程都可以接受信号，但是为了管理方便，通常不对 Worker 进程直接发送信号，所以我们依赖于 Master 进程，他必须把他的 pid 保存下来，为了新的 Master 使用 pid.bin 这个文件名，所以把老的 pid 文件改为 pid.oldbin。



热升级大致分为两步，按照新的要求编译好Nginx的二进制文件，通过信号，完成新老进程的平滑过渡，保证升级期间服务可用。







第一步：先查看原先编译的参数。-V可以查看编译时的参数。（-v是查看版本）

在新编译时，要将原有的模块参数也加上，否则原有的模块不会编译进去。

```
./nginx -V
```



- 第二步：开始编译，编译过程和[上篇](https://blog.csdn.net/gexiaoyizhimei/article/details/101567219)一致，只是增加了要添加模块的参数。



https://blog.csdn.net/gexiaoyizhimei/article/details/101650717

https://www.cnblogs.com/wupeixuan/p/12074007.html

# Nginx 安全配置规范



## 禁止IP访问

 一台服务器部署多个网站的时候，为了确保用户访问特定的网站，就要求用户使用域名访问，不能使用IP；另外，也可以防止一些未备案的域名解析到服务器，导入服务器被断网。 







## 隐藏版本号





# Nginx 反向代理和负载均衡



四层和七层负载均衡

- 所谓四层就是基于IP+端口的负载均衡；七层就是基于URL等应用层信息的负载均衡；同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。

- 二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；
- 三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址；
- 四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器；
- 七层通过虚拟的 URL 或 主机名 接收请求，然后再分配到真实的服务器。



我们最常见的 nginx location proxy_pass 反向代理，就是基于 URL 匹配将 HTTP 请求转到真实的后端服务。





### 在nginx内部处理3xx跳转



nginx反向代理，后端服务器可能返回 3XX 的redirect的response, Nginx会把这个请求直接返回给客户端。

现在我们的需求是让Nginx自己处理这个跳转，而客户端无感知。



### nginx负载均衡算法



#### **轮询 （round-robin）**

轮询为负载均衡中较为基础也较为简单的算法，它不需要配置额外参数。

假设配置文件中共有 $M$ 台服务器，该算法遍历服务器节点列表，并按节点次序每轮选择一台服务器处理请求。当所有节点均被调用过一次后，该算法将从第一个节点开始重新一轮遍历。

**特点**：由于该算法中每个请求按时间顺序逐一分配到不同的服务器处理，因此适用于服务器性能相近的集群情况，其中每个服务器承载相同的负载。但对于服务器性能不同的集群而言，该算法容易引发资源分配不合理等问题。



#### 加权轮询

```nginx
# 定义一个后端服务，由三个节点组成
upstream cluster  {
    server backend1-inc.example.com        weight=5;
    server backend2-inc.example.com:8080;
    server unix:/tmp/backend3;

    server backup1.example.com:8080   backup;
    server backup2.example.com:8080   backup;
}

server {
   location / {
   		proxy_set_header X-Real-IP $remote_addr;               //返回真实IP
   		proxy_pass http://cluster;                             //代理指向cluster 
    
}
}
```







**上游**

upstream 即上游的意思，是一个想对到概念，从客户端到中间的网络链路到服务器到链路中，可以将越接近客户到设备越理解成下游，相反到为上游。

所以如果只有一个upstream，可以将其为理解成转发客户到请求到服务器，然后响应服务器转发到客户端到过程。

**下游**





 `ngx_http_proxy_module` 模块可以使发到 nginx 的请求转发到真正的另外一个后端服务器上。





**反向代理时的头部处理**



在实际应用中，我们的后端服务器可能需要获取客户端用户的 ip 地址，比如做异地登陆的判断，或者统计 ip 访问次数等，通常情况下我们使用 request.getRemoteAddr() 就可以获取到客户端 ip。

但是当我们使用了 nginx 作为反向代理后，使用 request.getRemoteAddr() 获取到的就一直是 nginx 服务器的 ip 的地址。

经过反向代理后，由于在客户端和 web 服务器之间增加了中间层，因此 web 服务器无法直接拿到客户端的 ip，通过 $remote_addr 变量拿到的将是反向代理服务器的 ip 地址。



如果服务是直接暴露在公网上，根据TCP的原理通过socket是可以拿到真实的用户IP的。但是为了安全性和负载均衡的需要我们很少会直接把后端服务直接放在公网上，通常会在服务前置`Nginx`、`Haproxy`等反向代理软件，有时为了需要还会加多层代理，比如CDN和WAF等，这时如何能获取到用户的IP就成了问题，因为根据TCP的原理，反向代理时上一层和下一层代理建连，后层代理只能获取到上一层代理的IP，没法获取到用户的源IP。





`X-Forwarded-For`是 HTTP头的一个字段，最开始是由 `Squid`这个缓存代理软件引入，在客户端访问服务器的过程中如果需要经过HTTP代理或者负载均衡服务器，可以被用来获取最初发起请求的客户端的IP地址，如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用。 [RFC 7239](http://tools.ietf.org/html/rfc7239)（Forwarded HTTP Extension）是这个头信息的标准化版本。



X-Forwarded-For 格式：

```shell
X-Forwarded-For: <client>, <proxy1>, <proxy2>
```



- client：客户端的IP地址。
- proxy1, proxy2：如果一个请求经过了多个代理服务器，那么每一个代理服务器的IP地址都会被依次记录在内。也就是说，最右端的IP地址表示最近通过的代理服务器，而最左端的IP地址表示最初发起请求的客户端的IP地址。



**`X-Forwarded-For`只规定了这个字段的格式，并不代表这是代理服务器的默认行为，是否增加还要是具体配置。**



#### Nginx 处理 X-Forwarded-For

Nginx做反向代理时为了让后端服务能获取到真实的用户ip网上的教程大多会让增加下边两行配置：

```nginx
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
```

**$proxy_add_x_forwarded_for 变量的含义**

- 如果请求中不带X-Forwarded-For头，那么取`$remote_addr`的值；
- 如果请求中带X-Forwarded-For头，那么在X-Forwarded-For后追加`$remote_addr`，即: `X-Forwarded-For,$remote_addr`



因为`X-Forwarded-For`只是一个http的请求头，客户端很容易伪造一个 X-Forwarded-For 请求头。这时`Nginx`如果使用上边的配置的话由于`X-Forwarded-For`不为空，所以`Nginx`只会在现在值的基础上追加，这样后端服务在拿到头后根据约定取最左边ip话就会拿到一个伪造的IP，会有安全风险。

```shell
curl -H "X-Forwarded-For: 8.8.8.8" https://www.google.com 
```

由于请求头是不可靠的，我们不能信任客户端传过来头信息，那么如何解决呢？



TCP不像UDP必须经过3次握手，客户端的IP是无法伪造的，所以**最外层的代理**一定要取`$remote_addr`的值，对应配置：

```nginx
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $remote_addr;
```







# 初探 nginx 架构

nginx 在启动后，在 unix 系统中会以 daemon 的方式在后台运行，后台进程包含一个 master 进程和多个 worker 进程。我们也可以手动地关掉后台模式，让 nginx 在前台运行，并且通过配置让 nginx 取消 master 进程，从而可以使 nginx 以单进程方式运行。



很显然，生产环境下我们肯定不会这么做，所以关闭后台模式，一般是用来调试用的，在后面的章节里面，我们会详细地讲解如何调试nginx。

**当然nginx是以多进程的方式来工作的，当然nginx也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是nginx的默认方式。**







**为什么 Nginx 不使用多线程？**

- Apache: 创建多个进程或线程，而每个进程或线程都会为其分配 cpu 和内存（线程要比进程小的多，所以worker支持比perfork高的并发），并发过大会耗光服务器资源。

- Nginx: 采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量）(epoll)，不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换。所以才使得Nginx支持更高的并发。



Nginx 最核心的一个目的是要保持高可用性、高可靠性，而当 Nginx 如果使用的是多线程结构的时候，因为线程之间是共享同一个地址空间的，所以当某一个第三方模块引发了一个地址空间导致的段错误时、在地址越界出现时，会导致整个 Nginx 进程全部挂掉。而当采用多进程模型时，往往不会出现这样的问题。从下图可以看到 Nginx 在做进程设计时，同样遵循了实现高可用、高可靠这样的一个目的。





## Nginx进程模型



多进程中的 Nginx 进程架构如下图所示：



![Nginx进程结构](./assets/nginx-models.png)



nginx在启动后，会有一个`master`进程和多个`worker`进程。

- master进程主要用来管理worker进程，作用包括：
  - 接收来自外界的信号，向各worker进程发送信号。比如 reload 重载配置文件，重启nginx等。
  - 监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。

- worker进程：
  - worker才是真正的工作进程，处理基本的网络请求事件。各进程互相之间是独立的。
  - 一个请求，只可能在一个worker进程中处理。一个worker进程，不可能处理其它进程的请求。
  - Nginx 中还有两个特殊用途的进程：**缓存加载器进程（Cache Loader ）**和 **缓存管理器进程（Cache Manager）**
  - `cache loader`进程负责检测磁盘的缓存，且向内存数据库提供缓存元数据，`cache loader`在Nginx准备启动时，以一定的目录结构，遍历缓存内容的元数据，更新共享内存中的相关条目，**当准备完成后退出**。
  - `cache manager`进程主要负责缓存的过期管理和诊断。**一般存在于主进程的整个生命周期**，负责对缓存索引进行管理。通过缓存机制，可以提高对请求的响应效率，进一步降低网络压力。







master来管理worker进程，所以我们只需要与master进程通信就行了。master进程会接收来自外界发来的信号，再根据信号做不同的事情。

所以我们要控制nginx，只需要通过kill向master进程发送信号就行了。比如kill -HUP pid，则是告诉nginx，从容地重启nginx，我们一般用这个信号来重启nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。

master进程在接收到HUP信号后是怎么做的呢？首先master进程在接到信号后，会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker进程发送信号，告诉他们可以光荣退休了。

新的worker在启动后，就开始接收新的请求，而老的worker在收到来自master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。

当然，直接给master进程发送信号，这是比较老的操作方式，nginx在0.8版本之后，引入了一系列命令行参数，来方便我们管理。比如，./nginx -s reload，就是来重启nginx，./nginx -s stop，就是来停止nginx的运行。

如何做到的呢？

执行 nginx -s reload 命令时，其实是启动一个新的nginx进程，而新的nginx进程在解析到reload参数后，就知道我们的目的是控制nginx来重新加载配置文件了，它会向master进程发送信号，然后接下来的动作，就和我们直接向master进程发送信号一样了。



**work进程**

Nginx并不会为每一个连接新建一个进程来进行处理，相反，`worker`会从一个共享的监听套接字中获取新的请求，并在`worker`管理的Run-loop中处理请求。

Nginx启动时，将创建初始的监听套接字，接下来，当`worker`处理`HTTP`请求和响应时，会持续的接收、读取、以及写入套接字。

Run-loop是`worker`的核心，它的主要思想是异步任务处理，实现方式包括模块化、事件通知、回调函数、定时器等。总的原则就是尽可能的非阻塞。

关于`worker`的数量问题，通常的建议是：

- CPU密集型：比如处理大量的TCP/IP，SSL，或压缩时，Nginx `worker`进程的数量应当和CPU核的数量一致。
- 磁盘I/O密集型：提供文件内容，或者大量的代理，这种情况下，`worker`进程的数量可以是CPU核数的1.5或2倍。



每个 Worker 进程都是从 Master 进程fork过来，在 Master 进程里面，先建立好需要 listen 的 socket（listenfd）之后，然后再 fork 出多个 Worker 进程。

所有 Worker 进程的 listenfd 会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有 Worker 进程在注册 listenfd 读事件前抢互斥锁accept_mutex，抢到互斥锁的那个进程注册 listenfd 读事件，在读事件里调用 accept 接受该连接。

当一个 Worker 进程在 accept 这个连接之后，就开始读取、解析、处理请求，在产生数据后再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。

我们可以看到，一个请求完全由 Worker 进程来处理，而且只在一个 Worker 进程中处理。



Nginx 采用这种进程模型有什么好处呢？首先，对于每个 Worker 进程来说，独立的进程不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。

其次，采用独立的进程可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断， Master 进程则很快启动新的 Worker 进程。

当然， Worker 进程异常退出，肯定是程序出现了bug，异常退出会导致当前 Worker上的所有请求失败，不过不会影响到所有请求，所以降低了风险。好处还有很多，大家可以慢慢体会。





**异步非阻塞**



一个请求的完整过程。首先，请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。

具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧





# Nginx基础概念

Nginx是高度模块化的，各个功能都会封装在模块中。例如core模块、HTTP模块等。也可以自定义模块。

模块化是Nginx的一个重要特性，一方面可以很好的拆解各功能之间的耦合，另一方便让Nginx的扩展性得到很大提升。每个人都可以开发模块来适应实际遇到的场景



在Nginx中，模块分为`静态模块`和`动态模块`。其中对于动态模块是有一个数量的限制，不能超过`NGX_MAX_DYNAMIC_MODULES`，也就是128个。



# Nginx请求处理11阶段

Nginx的HTTP框架基本由1个核心模块`ngx_http_module`、两个HTTP模块(`ngx_http_core_module`、`nginx_http_upstream_module`)组成，负责调用其他HTTP模块来一起处理用户请求。



Nginx 处理请求的过程一共划分为 11 个阶段，按照执行顺序依次是 post-read、server-rewrite、find-config、rewrite、post-rewrite、preaccess、access、post-access、try-files、content 以及 log。



Nginx实际把http请求处理流程划分为了11个阶段，这样划分的原因是将请求的执行逻辑细分，以模块为单位进行处理，各个阶段可以包含任意多个http模块并以流水线的方式处理请求。这样做的好处是使处理过程更加灵活、降低耦合度。

可以让每个HTTP模块可以仅仅专注于完成一个独立，简单的功能。而一个请求的完整处理过程可以由多个HTTP模块共同合作完成。可以极大的提高多个模块合作的协同性，可测试性，可扩展性。

换言之，nginx在处理每一个http请求，和配置文件上的顺序没有关系。





# nginx 第三方模块







## 访问控制



### REALIP模块

`用途`：当本机 `Nginx` 处于反向代理后端时可以获取到用户的`真实IP地址`。

`使用`：`realip` 功能需要 `Nginx` 添加 `ngx_http_realip_module` 模块，默认情况下是不被编译，如果需要添加，请在编译时添加 `--with-http_realip_module` 选项开启它。



### GEOIP访问控制

对于在公网部署的应用，需要通过检测访问者的 IP ，来决定转发策略，或者是否访问。可以采用  ngx_http_geoip2_module 模块。

GeoIP2 是 MaxMind 公司推出的知名 IP 定位数据库，数据库每周更新。可以通过 [github](https://github.com/fengzhao-study-notes/maxmind-geoip/releases) 下载。



利用访问

nginx的版本比较重要，低于`1.9.11`版本的nginx无法使用动态模块，低于`1.11.5`版本的nginx编译动态模块时不支持`--with-compat`兼容参数，所以请保证您的nginx版本不低于`1.11.5`。



ngx_http_geoip2_module 





```shell
# 如果nginx是编译安装的，可以用nginx -V查看nginx源版本和编译参数

[root@stxz-elk-01 nginx-1.21.4]#
[root@stxz-elk-01 nginx-1.21.4]# /usr/local/nginx/sbin/nginx  -V
nginx version: nginx/1.21.4
built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC)
built with OpenSSL 1.0.2k-fips  26 Jan 2017
TLS SNI support enabled
configure arguments: --user=nginx --group=nginx --prefix=/usr/local/nginx/ --with-http_stub_status_module --with-http_ssl_module
[root@stxz-elk-01 nginx-1.21.4]#


# 下载对应版本的nginx源代码，然后


 ./configure                                     \
 --user=nginx --group=nginx                      \
 --prefix=/usr/local/nginx/                      \
 --with-http_stub_status_module                  \
 --with-http_ssl_module                          \
 --add-dynamic-module=./ngx_http_geoip2_module   \
 --with-stream                                   \
 --with-compat






wget -O /usr/local/nginx/geo/GeoLiteCountry.mmdb  https://github.com/fengzhao-study-notes/maxmind-geoip/releases/download/20220301/Country.mmdb


wget -O /usr/local/nginx/geo/GeoLiteCity.mmdb https://github.com/fengzhao-study-notes/maxmind-geoip/releases/download/20220301/City.mmdb


wget -O /usr/local/nginx/geo/GeoLiteASN.mmdb https://github.com/fengzhao-study-notes/maxmind-geoip/releases/download/20220301/ASN.mmdb



```

## 第三方压缩模块





在web应用中，为了节省流量，降低传输数据大小，提高传输效率，常用的压缩方式一般都是gzip，今天我们来介绍另外一种更高效的压缩方式brotli。

Brotli 是基于LZ77算法的一个现代变体、霍夫曼编码和二阶上下文建模。Google软件工程师在2015年9月发布了包含通用无损数据压缩的Brotli增强版本，特别侧重于HTTP压缩。

Google 在其博客中提到，Brotli 在压缩 HTML、CSS 和 JavaScript 文件时，通常能够比 GZIP 提供 17% 到 25% 的额外压缩比。

>  注意：使用算法的前提是启用了 https，因为 http 请求中 **request header** 里的 **Accept-Encoding: gzip, deflate** 是没有 br 的。
>
> 如果 Brotli 压缩生效，你应该会看到响应头中包含 `Content-Encoding: br`。







# nginx事件驱动模型



事件驱动模型是Nginx服务器保障完整功能和具有良好性能的重要机制之一。









### 惊群效应

当你往一群鸽子中间扔一块食物，虽然最终只有一个鸽子抢到食物，但所有鸽子都会被惊动来争夺，没有抢到食物的鸽子只好回去继续睡觉， 等待下一块食物到来。

**这样，每扔一块食物，都会惊动所有的鸽子，即为惊群。**

简单地说：就是扔一块食物，所有鸽子来抢，但最终只一个鸽子抢到了食物。

**语义分析：食物只有一块，最终只有一个鸽子抢到，但是惊动了所有鸽子，每个鸽子都跑过来，消耗了每个鸽子的能量。**

**（这个很符合达尔文的进化论，物种之间的竞争，适者生存。）**

在多进程/多线程等待同一资源时，也会出现惊群。即当某一资源可用时，多个进程/线程会惊醒，竞争资源。这就是操作系统中的惊群。





"惊群"简单地来讲，就是多个进程(线程)阻塞睡眠在某个系统调用上，在等待某个 fd(socket)的事件的到来。

当这个 fd(socket)的事件发生的时候，这些睡眠的进程(线程)就会被同时唤醒，多个进程(线程)从阻塞的系统调用上返回，这就是"惊群"现象。

**"惊群"被人诟病的是效率低下，大量的 CPU 时间浪费在被唤醒发现无事可做，然后又继续睡眠的反复切换上。**





# Nginx变量漫谈

这里基本上完全摘录自春哥的 [agentzh 的Nginx 教程](https://openresty.org/download/agentzh-nginx-tutorials-zhcn.html?utm_source=tool.lu)



Nginx 的配置文件使用的就是一门微型的编程语言，许多真实世界里的 Nginx 配置文件其实就是一个一个的小程序。

它在设计上受 Perl 和 Bourne Shell 这两种语言的影响很大。



熟悉 Perl、Bourne Shell、C/C++ 等命令式编程语言的朋友肯定知道，**变量说白了就是存放“值”的容器。**

而所谓“值”，在许多编程语言里，既可以是 `3.14` 这样的数值，也可以是 `hello world` 这样的字符串，甚至可以是像数组、哈希表这样的复杂数据结构。

<span color="blue">**然而在 Nginx 配置中，变量只能存放一种类型的值，因为也只存在一种类型的值，那就是字符串。**</span>



比如 `nginx.conf` 文件中有下面这一行配置：

```nginx
# 使用标准ngx_rewrite模块中的set配置指令对变量 $a 进行了赋值操作。
set $a "hello world";
```

Nginx 变量名前面有一个 `$` 符号，这是记法上的要求。**所有的 Nginx 变量在 Nginx 配置文件中引用时都须带上 `$` 前缀。**

这种表示方法和 Perl、PHP 这些语言是相似的。



虽然 `$` 这样的变量前缀修饰会让正统的 `Java` 和 `C#` 程序员不舒服，但这种表示方法的好处也是显而易见的，那就是可以直接把变量嵌入到字符串常量中以构造出新的字符串：

```nginx
# 声明一个变量a,并赋值为"hello"
set $a hello;

# 用变量a的值来声明变量b
set $b "$a, $a";

# 当前 $foo 变量的值保存在另一个用户变量 $orig_foo 中
set $orig_foo $foo;
```

这里我们通过已有的 Nginx 变量 `$a` 的值，来构造变量 `$b` 的值。

于是这两条指令顺序执行完之后，`$a` 的值是 `hello`，而 `$b` 的值则是 `hello, hello`

**这种技术在 Perl 世界里被称为“变量插值”（variable interpolation），它让专门的字符串拼接运算符变得不再那么必要。**

看一个比较完备的 nginx 配置文件示例：

```nginx
 server {
        listen 8080;

        location /test {
            set $foo hello;
        	// 使用echo配置指令将 $foo 变量的值作为当前请求的响应体输出
            echo "foo: $foo";
        }
    }


```

[nginx echo 模块](https://github.com/openresty/echo-nginx-module#readme)（这是一个第三方的nginx模块，如果是nginx，需要重新 [编译安装](https://blog.csdn.net/jeikerxiao/article/details/106763068)，不过在 openresty 已经编译进去了） 

```shell
# 使用curl访问这个地址，响应体返回nginx配置文件中声明的变量值
curl 'http://localhost:8080/test'
foo: hello
```



我们看到， [echo](http://wiki.nginx.org/HttpEchoModule#echo) 配置指令的参数也支持“变量插值”。不过，需要说明的是，并非所有的配置指令都支持“变量插值”。

> 事实上，指令参数是否允许”变量插值”，取决于该指令的实现模块。



## Nginx 变量的规则



- **Nginx 变量的创建和赋值操作发生在全然不同的时间阶段：**
  - **Nginx 变量的创建只能发生在 Nginx 配置加载的时候，或者说 Nginx 启动的时候；(Nginx启动的时候就会读取配置文件并加载)**
  - **Nginx 变量赋值操作则只会发生在请求实际处理的时候。**
  - 这意味着不创建而直接使用变量会导致启动失败，同时也意味着我们无法在请求处理时动态地创建新的 Nginx 变量。

- **Nginx 变量一旦创建，其变量名的可见范围就是整个 Nginx 配置，甚至可以跨越不同虚拟主机的 `server` 配置块。**

- **Nginx 变量名的可见范围虽然是整个配置，但每个请求都有所有变量的独立副本，或者说都有各变量用来存放值的容器的独立副本，彼此互不干扰。**

```nginx
   server {
        listen 8080;
        include mime.types;
		default_type text/html; 
		
        location /foo {
            echo "foo = [$foo]";
        }

        location /bar {
            set $foo 32;
            echo "foo = [$foo]";
        }
    }
```

这里我们在 `location /bar` 中用 `set` 指令创建了变量 `$foo`，于是在整个配置文件中这个变量都是可见的。

因此我们可以在 `location /foo` 中直接引用这个变量而不用担心 Nginx 会报错。



```shell
# 由于 set 指令因为是在 location /bar 中使用的，所以赋值操作只会在访问 /bar 的请求中执行。
$ curl 'http://localhost:8080/foo'
    foo = []
    
# 这个URL匹配到 location /bar，所以成功使用set赋值
$ curl 'http://localhost:8080/bar'
    foo = [32]
    
# 即使前面请求了这两个URL，再次请求/foo。依然是空的。因为各个请求都有自己独立的 $foo 变量的副本。
$ curl 'http://localhost:8080/foo'
    foo = []
```



**对于 Nginx 新手来说，最常见的错误之一，就是将 Nginx 变量理解成某种在请求之间全局共享的东西，或者说“全局变量”。**

**而事实上，Nginx 变量的生命期是不可能跨越请求边界的。**



### location 内部跳转



**关于 Nginx 变量的另一个常见误区是认为 "变量容器的生命期，是与 `location` 配置块绑定的"。其实不然。**我们来看一个涉及“内部跳转”的例子：

```nginx
   server {
        listen 8080;
		include mime.types;
		default_type text/html;
        location /foo {
        
            set $a hello;
        	# 如果直接请求/foo，则发生内部跳转，跳转到下面那个location
            echo_exec /bar;
        }

        location /bar {
            echo "a = [$a]";
        }
    }

```



这里我们在 `location /foo` 中，使用第三方模块 [ngx_echo](http://wiki.nginx.org/HttpEchoModule) 提供的 [echo_exec](http://wiki.nginx.org/HttpEchoModule#echo_exec) 配置指令，发起到 `location /bar` 的“内部跳转”。

**所谓“内部跳转”，就是在处理请求的过程中，在服务器内部，从一个 `location` 跳转到另一个 `location` 的过程。**

**这不同于利用 HTTP 状态码 `301` 和 `302` 所进行的“外部跳转”。**

**因为后者是由 HTTP 客户端配合进行跳转的，而且在客户端，用户可以通过浏览器地址栏这样的界面，看到请求的 URL 地址发生了变化。**

内部跳转和 `Bourne Shell`（或 `Bash`）中的 `exec` 命令很像，都是“有去无回”。另一个相近的例子是 `C` 语言中的 `goto` 语句。



对于上面的例子，如果请求的是 `/foo` 这个接口，那么整个工作流程是这样的：

- 先在 `location /foo` 中通过 [set](http://wiki.nginx.org/HttpRewriteModule#set) 指令将 `$a` 变量的值赋为字符串 `hello`
- 后通过 [echo_exec](http://wiki.nginx.org/HttpEchoModule#echo_exec) 指令发起内部跳转，又进入到 `location /bar` 中，再输出 `$a` 变量的值。因为 `$a` 还是原来的 `$a`(hello)。

如果客户端直接请求 `/bar` 接口，就会得到空的 `$a` 变量的值，因为它依赖于 `location /foo` 来对 `$a` 进行初始化。





**一个请求在其处理过程中，即使经历多个不同的 `location` 配置块，它使用的还是同一套 Nginx 变量的副本。**

值得一提的是，标准 [ngx_rewrite](http://wiki.nginx.org/HttpRewriteModule) 模块的 [rewrite](http://wiki.nginx.org/HttpRewriteModule#rewrite) 配置指令其实也可以发起“内部跳转”，例如上面那个例子用 [rewrite](http://wiki.nginx.org/HttpRewriteModule#rewrite) 配置指令可以改写成下面这样的形式

```nginx
 server {
        listen 8080;
		include mime.types;
		default_type text/html;
        location /foo {
            set $a hello;
            rewrite ^ /bar;
        }

        location /bar {
            echo "a = [$a]";
        }
    }
```

从上面这个例子我们看到，Nginx 变量值容器的生命期是与当前正在处理的请求绑定的，而与 `location` 无关。



前面我们接触到的都是通过 [set](http://wiki.nginx.org/HttpRewriteModule#set) 指令隐式创建的 Nginx 变量。这些变量我们一般称为“用户自定义变量”，或者更简单一些，“用户变量”。

既然有“用户自定义变量”，自然也就有由 Nginx 核心和各个 Nginx 模块提供的“预定义变量”，或者说“内建变量”（builtin variables）。



### nginx 内置变量

所有的 nginx 内置变量都可以在[官方文档](http://nginx.org/en/docs/varindex.html)中找到。Nginx 内建变量最常见的用途就是获取关于请求或响应的各种信息。

例如由 [ngx_http_core](http://nginx.org/en/docs/http/ngx_http_core_module.html) 模块提供的内建变量：

- [$uri](http://wiki.nginx.org/HttpCoreModule#.24uri)，可以用来获取当前请求的 URI（经过解码，并且不含请求参数）。
- [$request_uri](http://wiki.nginx.org/HttpCoreModule#.24request_uri) 则用来获取请求最原始的 URI （未经解码，并且包含请求参数）。

比如：

```shell
  location /test {
        echo "uri = $uri";
        echo "request_uri = $request_uri";
    }
```

在这个例子中，把 [$uri](http://wiki.nginx.org/HttpCoreModule#.24uri) 和 [$request_uri](http://wiki.nginx.org/HttpCoreModule#.24request_uri) 的值输出到响应体中。

```shell
 $ curl 'http://localhost:8080/test'
    uri = /test
    request_uri = /test

$ curl 'http://localhost:8080/test?a=3&b=4'
    uri = /test
    request_uri = /test?a=3&b=4

$ curl 'http://localhost:8080/test/hello%20world?a=3&b=4'
    uri = /test/hello world
    request_uri = /test/hello%20world?a=3&b=4
```



另一个特别常用的内建变量其实并不是单独一个变量，而是有无限多变种的一群变量，即名字以 `arg_` 开头的所有变量。

**一个例子是 `$arg_name`，这个变量的值是当前请求名为 `name` 的 URI 参数的值，而且还是未解码的原始形式的值。**

```nginx
location /test {
        echo "name: $arg_name";
        echo "class: $arg_class";
    }
```

在命令行上使用各种参数组合去请求这个 `/test` 接口：

```shell
$ curl 'http://localhost:8080/test'
    name: 
    class: 

$ curl 'http://localhost:8080/test?name=Tom&class=3'
    name: Tom
    class: 3

$ curl 'http://localhost:8080/test?name=hello%20world&class=9'
    name: hello%20world
    class: 9
```

其实 `$arg_name` 不仅可以匹配 `name` 参数，也可以匹配 `NAME` 参数，抑或是 `Name`，等等：

> **Nginx 会在匹配参数名之前，自动把原始请求中的参数名调整为全部小写的形式。**

```shell
$ curl 'http://localhost:8080/test?NAME=Marry'
    name: Marry
    class: 

$ curl 'http://localhost:8080/test?Name=Jimmy'
    name: Jimmy
    class: 
```

如果你想对 URI 参数值中的 `%XX` 这样的编码序列进行解码，可以使用第三方 [ngx_set_misc](http://wiki.nginx.org/HttpSetMiscModule) 模块提供的 [set_unescape_uri](http://wiki.nginx.org/HttpSetMiscModule#set_unescape_uri) 配置指令：

```nginx
 location /test {
        set_unescape_uri $name $arg_name;
        set_unescape_uri $class $arg_class;

        echo "name: $name";
        echo "class: $class";
    }
```



现在我们再看一下效果：

```shell
$ curl 'http://localhost:8080/test?name=hello%20world&class=9'
    name: hello world
    class: 9
# 空格果然被解码出来
```

从这个例⼦我们同时可以看到，这个 set_unescape_uri 指令也像 set 指令那样，拥有⾃动创建 Nginx 变量的功能。

需要指出的是，许多内建变量都是只读的，比如我们刚才介绍的 [$uri](http://wiki.nginx.org/HttpCoreModule#.24uri) 和 [$request_uri](http://wiki.nginx.org/HttpCoreModule#.24request_uri). 对只读变量进行赋值是应当绝对避免的，因为会有意想不到的后果，比如：

```nginx
location /bad {
	set $uri /blah;
  	echo $uri;
  }
```

这个有问题的配置会让 Nginx 在启动的时候报出一条令人匪夷所思的错误：

```
[emerg] the duplicate "uri" variable in ...

```











# Nginx 配置指令的执行顺序



大多数 Nginx 新手都会频繁遇到这样一个困惑，那就是当同一个 `location` 配置块使用了多个 Nginx 模块的配置指令时，这些指令的执行顺序很可能会跟它们的书写顺序大相径庭。

于是许多人选择了“试错法”，然后他们的配置文件就时常被改得一片狼藉。这个系列的教程就旨在帮助读者逐步地理解这些配置指令背后的执行时间和先后顺序的奥秘。



```shell
location /test {
   set $a 32;
   echo $a;
   set $a 56;
   echo $a;
}
```



从这个例子的本意来看，我们期望的输出是一行 `32` 和一行 `56`，因为我们第一次用 [echo](http://wiki.nginx.org/HttpEchoModule#echo) 配置指令输出了 `$a` 变量的值以后，又紧接着使用 [set](http://wiki.nginx.org/HttpRewriteModule#set) 配置指令修改了 `$a`. 

事实并非如此：

```
    $ curl 'http://localhost:8080/test'
    56
    56
```













# API限速



>  **面试题：给定一个公共API，限制每个用户每秒只能调用1000次，如何实现？这一个经典的API限速问题(API rate limiting)。**

在高并发的分布式系统，如大型电商系统中，由于接口 API 无法控制上游调用方的行为，因此当瞬间请求量突增时，会导致服务器占用过多资源，发生响应速度降低、超时乃至宕机，甚至引发雪崩造成整个系统不可用。

面对这种情况，一方面我们会提升 API 的吞吐量和 QPS（Query Per Second 每秒查询量），但总归会有上限。

另一方面为了应对巨大流量的瞬间提交，我们需要做对应的限流处理，也就是对请求量进行限制，对于超出限制部分的请求作出快速拒绝、快速失败、丢弃处理，以保证本服务以及下游资源系统的稳定。

**在应对秒杀，抢购等高并发压力的场景时，限流已经成为了标配技术解决方案**，为保证系统的平稳运行起到了关键性的作用。不管应用场景是哪种，**限流无非就是针对超过预期的流量，通过预先设定的限流规则选择性的对某些请求进行限流“熔断”**。

通过限流，我们可以很好地控制系统的**QPS**，从而达到保护系统的目的。接下来的内容将会介绍一下常用的限流算法以及他们各自的特点：



## **限流概述**

在业务安全性方面，我们常常会用到接口限流，主要是为了防止系统压力过大、保证每个用户请求的资源保持均匀以及屏蔽恶意请求。

在开发高并发系统时，有三把利器用来保护系统：缓存、降级和限流。那么何为限流呢？顾名思义，限流就是限制流量，就像你宽带包了1个G的流量，用完了就没了。

通过限流，我们可以很好地控制系统的qps，从而达到保护系统的目的。

- 缓存：缓存的目的是提升系统访问速度和增大系统处理容量
- 降级：降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行
- 限流：限流的目的是通过对并发访问/请求进行限速，或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务、排队或等待、降级等处理

我们经常在调别人的接口的时候会发现有限制，比如微信公众平台接口、百度API Store、聚合API等等这样的，对方会限制每天最多调多少次或者每分钟最多调多少次。

比如，[腾讯云的API接口](https://cloud.tencent.com/document/api/213/15707) 就是对请求限流为 20 次/秒

几个常见的场景如下：

- 恶意注册
- 爬虫的过度抓取
- 秒杀场景

目前实现API接口限流的方式有几种常见的，简单来说原理很简单，无非是在一个固定的时间段内，限制API的请求速率，一般来说是根据IP，如果是登录用户的话，还可以用用户的ID。



**限制了后怎么做**

对于恶意请求，假如对方的反反爬虫做的一般的话，完全可以直接将对方的IP加入黑名单，但如果对方用的IP代理，那就不是限流这个方案能解决的了，需要更高级的反爬虫方案。

但是我想提一点，对方既然爬了你的数据，肯定有对方的用处，假如对方没有恶意，请求频率也没有让你的机器有太多压力，那也就算了，毕竟你可能也在爬其它人的数据，大家都是搞技术的，没准对方背着万恶的KPI呢。

但是，如果对方恶意爬取，那么你完全可以在探测到对方的请求之后，返回空数据，甚至以假乱真的数据欺骗对方，让对方无利可图，对方也可能就会主动放弃了。



**如何设计API的限流**

可用性和可靠性对于所有 Web 应用程序和 API 服务至关重要。如果您提供 API 服务，您可能体会过流量突增对服务质量的影响，甚至可能造成服务中断。

限制流量可以使 API 服务在下面的场景中更可靠：

- 某个用户直接或间接造成了流量飙升，我们需要确保对其他用户服务可用。

- 某个用户向 API 服务发送大量请求。 或者更糟的是，某个用户试图恶意冲垮服务器。

- 用户发送了大量低优先级请求，但我们希望确保不会影响其他高优先级请求。 例如，发送大量分析数据请求的用户可能会影响其他用户的关键事务。

- 系统内部产生错误，导致无法处理所有请求，不得不丢弃低优先级的请求。



**常见的限流算法和策略**

**计数器算法**

计数器算法是限流算法里最简单也是最容易实现的一种算法。

比如我们规定，对于A接口来说，我们1分钟的访问次数不能超过100个。（指所有并发用户一起）

那么我们可以这么做：在一开始的时候，我们可以设置一个计数器counter，每当一个请求过来的时候，counter就加1，如果counter的值大于100并且该请求与第一个请求的间隔时间还在1分钟之内，那么说明请求数过多；如果该请求与第一个请求的间隔时间大于1分钟，且counter的值还在限流范围内，那么就重置 counter。

- 将时间划分为固定的窗口大小，例如1s

- 在窗口时间段内，每来一个请求，对计数器加1。

- 当计数器达到设定限制后，该窗口时间内的之后的请求都被丢弃处理。

- 该窗口时间结束后，计数器清零，从新开始计数。如上图所示，10s内限制1000个请求，在第11s的时候计数器会从0重新开始计数。

  

**优点**：实现简单，并且内存占用小，我们只需要存储时间窗口中的计数即可；计数器限流方式比较粗暴，一次访问就增加一次计数，在系统内设置每 N 秒的访问量，超过访问量的访问直接丢弃，从而实现限流访问。 

**缺点**：流量曲线可能不够平滑，有“突刺现象” ”和 临界问题“ 。

- 突刺现象：如果在单位时间1s内允许100个请求，在10ms已经通过了100个请求，那后面的990ms，只能眼巴巴的把请求拒绝，我们把这种现象称为"突刺现象"。

- 临界问题：假设我们限流规则为每秒钟不超过 100 次接口请求，第一个 1s 时间窗口内，100 次接口请求都集中在最后的 10ms 内，在第二个 1s 的时间窗口内，100 次接口请求都集中在最开始的 10ms 内，虽然两个时间窗口内流量都符合限流要求，但是在这两个时间窗口临界的 20ms 内会集中有 200 次接口请求。如果不做限流，集中在这 20ms 内的 200 次请求就有可能压垮系统。





**滑动窗口算法**

滑动窗口算法是计数器算法的一种改进，将原来的一个时间窗口划分成多个时间窗口，并且不断向右滑动该窗口。

流量经过滑动时间窗口算法整形之后，可以保证任意时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑，可以部分解决上面提到的临界突发流量问题。

对比固定时间窗口限流算法，滑动时间窗口限流算法的时间窗口是持续滑动的，并且除了需要一个计数器来记录时间窗口内接口请求次数之外，还需要记录在时间窗口内每个接口请求到达的时间点，对内存的占用会比较多。

滑动窗口计数法的思路是：

1. 将时间划分为细粒度的区间，每个区间维持一个计数器，每进入一个请求则将计数器加一；
2. 多个区间组成一个时间窗口，每流逝一个区间时间后，则抛弃最老的一个区间，纳入新区间。如图中示例的窗口 T1 变为窗口 T2；
3. 若当前窗口的区间计数器总和超过设定的限制数量，则本窗口内的后续请求都被丢弃。



# Nginx防止恶意解析

在实际生产环境中经常会遇到一些不是自己的域名访问的内容与自己网站一样，检查域名没有绑定在服务器中。

但域名是解析到自己服务器ip的，使用http和https可以访问自己的网站内容,



**现象：**域名不是自己的，站点没绑定这个域名,使用域名http或者https可以访问到自己站点内容。

**原因：**原因是因为服务器ip可以访问，即便没绑定这个域名，只要解析到服务器ip就会访问到第一个站点









# Nginx 避免 IP 访问时证书暴露域名





预读SNI，非法请求直接拒绝握手



```nginx
stream {
    map $ssl_preread_server_name $backend_name {
        api.myserver.com api;
        default bad;
    }
    
    upstream api {
        server 127.0.0.1:777;
    }

    upstream bad {
        server 127.0.0.1:400;
    }

    server {
        listen 443 reuseport;
        listen [::]:443 reuseport;
        proxy_pass $backend_name;
        ssl_preread on;
    }
}

http {
    server {
        listen 777 ssl;

        # do something
    }

    server {
        listen  400 ssl;

        # 拒绝握手
        ssl_reject_handshake on;
    }
}

```



# ssl_ciphers

命名规则概述

`ssl_ciphers` 指令的语法格式遵循 OpenSSL 的规则，它允许你以一种简洁且强大的方式定义服务器支持的加密套件列表及其优先级。

`ssl_ciphers` 规则由一个或多个**指令**组成，这些指令通过**冒号 `:`** 分隔。每条指令可以是一个**简短的名称**、一个**类别**或一个**操作符**。

OpenSSL 会从左到右依次处理这些指令，根据它们的顺序和含义来构建最终的密码套件列表。





OpenSSL 将密码套件分为多个类别，这些是配置中最常用的命名方式：

- **`HIGH`**: 包含密钥长度大于 128 位的密码套件，被认为是高强度的安全算法。
- **`MEDIUM`**: 包含密钥长度为 128 位的密码套件，如一些 AES-128 算法。
- **`LOW`**: 包含密钥长度小于 128 位的密码套件，如 64 位的 DES 算法，通常不建议使用。
- **`ALL`**: 包含所有可用的密码套件。
- **`DEFAULT`**: OpenSSL 默认的密码套件列表。
- **`3DES`**: 包含所有使用 3DES 算法的密码套件。
- **`SHA`**, **`SHA256`**, **`SHA384`**: 包含使用特定 SHA 哈希算法的密码套件。
- **`aRSA`**: 包含使用 RSA 算法进行认证的密码套件。
- **`kECDHE`**: 包含使用 ECDHE 算法进行密钥交换的密码套件，这类算法提供前向保密性。



加密套件是指在SSL通信中，服务器和客户端所使用的加密算法的组合。在SSL握手初期，客户端将自身支持的加密套件列表发送给服务器；

在握手阶段，服务器根据自己的配置从中尽可能的选出一个套件，作为之后所要使用的加密方式。



每种加密套件中支持的加密算法大多包含了如下信息：

- 密钥交换算法：用于决定客户端与服务器之间在握手的过程中如何认证。
  - 这是握手的第一步，用来**安全地协商一个会话密钥**。这个密钥是临时的，只用于本次通信。
  - 这里使用非对称加密算法来生成会话密钥，因为非对称算法不会将重要数据在通信中传输。用到的算法包括RSA、Diffie-Hellman和ECDHE。
  - **RSA**：传统算法，但**缺乏前向保密性**。
  - **ECDHE**：现代算法，**提供前向保密性**，是目前推荐的最佳实践。
- 身份验证/签名算法：用于CA证书签名。用到的算法包括RSA和DSS。
  - **ECDSA**：基于椭圆曲线的数字签名算法，比传统的 RSA 更高效和安全。
  - **RSA**：也用于身份验证，同样非常常用。
- 加密算法：用于对数据进行加密传输。
  - 一般有对称加和非对称加密，但是非对称加密算法太耗性能，再者有些非对称加密算法有内容长度的限制，所以真正要传输的数据会使用**对称加密**来进行加密。算法名称后通常带密钥的长度和加密模式（GCM和CBC）。
  - 用到的算法包括：AES_128、AES_256、AES_128_CBC、AES_256_CBC、AES_128_GCM、AES_256_GCM和ChaCha20-Poly1305。
- 完整性校验算法：用于校验消息的完整性。用到的算法包括SHA、SHA256和SHA384。







加密套件命名规则：

密钥交换算法-身份验证/签名算法-对称加密算法-完整性校验/哈希算法



为什么有的是TLS_ECDHE开头，有的直接ECDHE开头呢

`ECDHE-RSA-AES256-GCM-SHA384`

`TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256`



这是由 **IETF (互联网工程任务组)** 在 **TLS 协议**的官方标准（RFCs）中定义的规范化命名方式。这种命名更加正式、完整，通常用于协议文档和程序代码中。

举例：`TLS_<密钥交换算法>_WITH_<对称加密算法>_<消息认证算法>`:`TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256`

这种命名方式的优点是：

- **完整性**：它包含了所有关键信息，清晰地表明这个套件是用于 TLS 协议的。
- **标准化**：是官方标准，不会产生歧义。



这是 **OpenSSL** 库和基于 OpenSSL 的软件（如 **Nginx、Apache**）所使用的、更简洁、更方便的命名方式。这种命名通常用于配置文件和命令行工具中。

举例：`<密钥交换算法>-<认证算法>-<对称加密算法>-<哈希算法>`:`ECDHE-RSA-AES256-GCM-SHA384`

这种命名方式的优点是：

- **简洁性**：更短，易于阅读和输入。
- **实用性**：在日常配置中更为常见。



```
ssl_ciphers 'ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:!aNULL:!eNULL:!RC4:!MD5:!RSA';
```









# testssl.sh 

安全套接层（SSL）和传输层安全（TLS）加密用于通过互联网提供通信安全（传输加密）和来保护网络流量和互联网上的隐私，用于诸如网络，电子邮件，即时消息（IM）和一些虚拟专用网络（VPN）。

因此，TLS安全配置很重要，应花时间学习如何识别常见的漏洞和安全配置错误。



testssl.sh是我们首选的测试工具，它涵盖了TLS和SSL评估所需的所有测试所需工具，并定期更新。

以前SSL检测常用工具就是ssllabs的：https://www.ssllabs.com/ssltest/ 以及国内的https://myssl.com/。检测方法很简单，输入在线检测即可。

今天在网上有发现一款好用的SSL检测脚本：testssl.sh：https://testssl.sh/





# NGX_LUA 基础

OpenResty通过汇聚各种设计精良的Nginx模块（主要由OpenResty团队自主开发）将Nginx变成一个强大的通用Web应用平台。

这样，Web开发人员和系统工程师可以使用Lua脚本语言调动Nginx支持的各种C以及Lua模块，快速构造出足以胜任10KB乃至1000KB以上单机并发连接的高性能Web应用系统。





在OpenResty中，每个Worker进程使用一个**==Lua VM（Lua虚拟机==**），当请求被分配到Worker时，将在这个Lua VM中创建一个协程，协程之间数据隔离，每个协程都具有独立的全局变量。

ngx_lua是将Lua嵌入Nginx，让Nginx执行Lua脚本，并且高并发、非阻塞地处理各种请求。Lua内置协程可以很好地将异步回调转换成顺序调用的形式。

ngx_lua在Lua中进行的IO操作都会委托给Nginx的事件模型，从而实现非阻塞调用。

开发者可以采用串行的方式编写程序，ngx_lua会在进行阻塞的IO操作时自动中断，保存上下文，然后将IO操作委托给Nginx事件处理机制，在IO操作完成后，ngx_lua会恢复上下文，程序继续执行，这些操作对用户程序都是透明的。

每个Nginx的Worker进程持有一个Lua解释器或LuaJIT实例，被这个Worker处理的所有请求共享这个实例。每个请求的context上下文会被Lua轻量级的协程分隔，从而保证各个请求是独立的。



（1）每个Worker（工作进程）创建一个LuaJIT VM，Worker内所有协程共享VM。

（2）将Nginx I/O原语封装后注入Lua VM，允许Lua代码直接访问。

（3）每个外部请求都由一个Lua协程处理，协程之间数据隔离。

（4）Lua代码调用I/O操作等异步接口时会挂起当前协程（并保护上下文数据），而不阻塞Worker进程。

（5）I/O等异步操作完成时还原协程相关的上下文数据，并继续运行。



每个Nginx Worker进程持有一个Lua解释器或者LuaJIT实例，被这个Worker处理的所有请求共享这个实例。每个请求的Context会被Lua轻量级的协程分割，从而保证各个请求是独立的。

ngx_lua采用`onecoroutine-per-request`的处理模型，对于每个用户请求，ngx_lua会唤醒一个协程用于执行用户代码处理请求，当请求处理完成后，这个协程会被销毁。每个协程都有一个独立的全局环境（变量空间），继承于全局共享的、只读的公共数据。

所以，被用户代码注入全局空间的任何变量都不会影响其他请求的处理，并且这些变量在请求处理完成后会被释放，这样就保证所有的用户代码都运行在一个sandbox（沙箱）中，这个沙箱与请求具有相同的生命周期。

得益于Lua协程的支持，ngx_lua在处理10000个并发请求时只需要很少的内存。根据测试，ngx_lua处理每个请求只需要2KB的内存，如果使用LuaJIT就会更少。所以ngx_lua非常适合用于实现可扩展的、高并发的服务。



# 健康检查

背景：使用Openresty作为网关进行动态节点IP负载均衡时，要求网关有能力在负载均衡之前摘除掉有问题的节点。所以网关需要一定的健康检查能力。

lua-resty-healthcheck是一个在OpenResty生态中大放异彩的组件，它允许开发者执行主动和被动的健康检查，监测任意目标主机的状态。

借助其强大的API和lua-resty-worker-events库的支持，它可以无缝地集成到你的高性能Web服务器或API网关中，为系统的稳定性保驾护航。







# Nginx REUSEPORT 

Linux 3.9 版本引入的 `SO_REUSEPORT` 套接字选项是一个重要的网络性能特性。

**它允许多个套接字（通常由同一个进程内的不同线程或不同进程创建）绑定到完全相同的地址和端口（即 `bind()` 到相同的 IP 地址和端口号）**。



当一个新连接请求到达绑定了该端口的服务器时，内核会根据 `SO_REUSEPORT` 套接字组内的规则，将这个新连接请求**均衡地**分发给其中一个监听套接字。

这个分发策略通常是**轮询（Round-Robin）**或**基于 CPU 亲和性（CPU affinity）**的，这取决于内核的具体实现和配置。



2013 年 Linux 内核添加了 reuseport 功能后，nginx 在 2015 年，1.9.1 版本也增加对应功能的支持，nginx 开启 reuseport 功能后，性能是原来的 2-3 倍，效果可谓立竿见影！



https://blog.flipkart.tech/linux-tcp-so-reuseport-usage-and-implementation-6bfbf642885a

https://lwn.net/Articles/542629/



因为配置文件设置了 `worker_processes 4` 需要启动 4 个子进程， nginx 进程发现配置文件关键字 listen 后添加了 reuseport 关键字，那么主进程先创建 4 个 socket 并设置 SO_REUSEPORT 选项，然后进行 bind 和 listen。

当 fork 子进程时，子进程拷贝了父进程的这 4 个 socket，所以你看到每个子进程都有相同 LISTEN 的 socket fd（6，7，8，9）。



尝试在一个nginx上启用了这一配置参数，前后对比，发现以下几个方面优化效果明显：

- CPU负载从30下降到8
- context switch从60K下降到40k
- cpu usage下降
- nginx服务平均延迟下降（单个请求的最高延迟有可能会增加，详见文章最后说明和链接）
- nginx慢请求数量下降



```nginx
server {
        listen 80 reuseport;
        listen 443 ssl http2 reuseport;
        server_name   xxx.xxx.com;
        charset utf-8;
}   
# 注意：同一个nginx实例下针对同一个IP+端口，只需要其中一个设置了reuseport即可全部生效。
```



# Nginx开发





## 头文件



使用C语言定制开发 Nginx 必须要包含两个头文件，它们含有绝大部分必须的宏、类型定义和函数声明等功能代码：

```c
#include <ngx_coinfig.h>  
#include <ngx_core.h>
```

- `ngx_config.h` 是 Nginx 的配置头文件，定义了与平台相关的宏和基本类型。它的主要目的是确保 Nginx 在不同操作系统和编译器环境下的兼容性。

  - **平台检测宏**：定义了操作系统的类型（如 Linux、Windows、FreeBSD 等）。定义了编译器的特性（如 GCC、MSVC 等）。

  - **基本类型定义** ：定义了跨平台的基本数据类型，例如 `ngx_int_t`、`ngx_uint_t` 等。

  - **编译选项** ：控制调试模式、优化级别等编译选项。

     

- `ngx_core.h` 是 Nginx 的核心头文件，包含了 Nginx 框架中绝大部分的基础定义和功能声明。它是开发 Nginx 模块时最重要的头文件之一。

  - **核心数据结构**：定义了 Nginx 中的核心数据结构，例如 `ngx_module_t`（模块结构）、`ngx_pool_t`（内存池）、`ngx_log_t`（日志）等。
  - **函数声明**：声明了 Nginx 核心功能的函数，例如内存分配、日志记录、字符串操作等。
  - **宏定义**：提供了许多常用的宏，例如 `ngx_min()`、`ngx_max()`、`ngx_align()` 等。



在开发 Nginx 的 HTTP 功能模块时，还需要引入与 HTTP 协议相关的头文件。这些头文件提供了处理 HTTP 请求、响应、连接等功能所需的定义和接口。

- **`ngx_http.h`**是 Nginx HTTP 模块开发的核心头文件，包含了绝大部分与 HTTP 协议相关的定义和功能。
  - 定义了 HTTP 模块的结构体（如 `ngx_http_module_t`）。
  - 声明了处理 HTTP 请求和响应的函数。
  - 提供了 HTTP 请求上下文（`ngx_http_request_t`）的定义。
  - 包含了 HTTP 状态码、方法、头部字段等常量。

- **`ngx_http_core_module.h`** 是定义了 Nginx HTTP 核心模块的功能和数据结构。
  - 定义了 HTTP 请求的阶段（如 `NGX_HTTP_POST_READ_PHASE`、`NGX_HTTP_CONTENT_PHASE` 等）。
  - 提供了核心模块的配置结构体（如 `ngx_http_core_loc_conf_t`）。
  - 声明了与 HTTP 配置相关的函数。

- **`ngx_http_request.h`** 专注于 HTTP 请求的处理，定义了请求对象（`ngx_http_request_t`）及其相关操作。
  - 定义了请求阶段和回调函数的注册机制。
  - 提供了对 HTTP 请求头、请求体、URI 等的访问接口。
- **`ngx_http_variables.h`** 支持自定义 HTTP 变量。
  - 支持动态生成变量值。
  - 提供了定义和使用变量的接口。







## 环境信息





头文件 `src/core/ngx_config.h` （实际上是 `./objs/ngx_auto_config.h`）里包含了一系列运行环境信息。在 Nginx 开发时使用它们可以让程序更具可移植性。



 

## 内存池

内存池是大型软件里常用的一种技术，它是对象池模式的具体应用：一次性向系统申请大块的内存，内部自行切割分配使用，最后再一次归还系统。减少系统调用次数，很好的避免内存碎片。

`ngx_pool_s` 是 Nginx 内存池的核心数据结构，用于为每个 TCP/HTTP 请求创建一个独立的内存池。这种设计的主要目的是优化内存管理，提升性能，并减少频繁分配和释放内存所带来的开销。

每个请求都有自己的独立内存池，因此不需要手动管理内存的分配和释放。在请求结束时，只需销毁内存池即可，避免了内存泄漏的风险。

- **减少内存碎片** ：通过预分配大块内存，减少了频繁分配和释放小块内存导致的内存碎片。
- **降低系统调用开销** ：内存池减少了对操作系统内存分配函数（如 `malloc` 和 `free`）的调用次数。
- **内存隔离：**每个请求的内存池是独立的，互不干扰。即使某个请求的内存池出现问题，也不会影响其他请求。

```c
// \nginx-1.27.4\src\core\ngx_core.h


// Nginx 源代码中定义的一些核心数据结构的类型别名（typedefs）。通过使用 typedef 关键字，代码为这些常用的结构体类型创建了更简洁的别名。这样做提高了代码的可读性，并减少了重复输入完整结构体名称的需求。
// ngx_pool_t: 代表 Nginx 的内存池。Nginx 使用自定义的内存池管理机制来高效地分配和释放内存，减少系统调用，提高性能。
// 通过 typedef，我们将 ngx_pool_t 定义为 struct ngx_pool_s 的一个别名。这意味着在代码中，我们可以使用 ngx_pool_t 来声明变量，而不需要每次都写完整的 struct ngx_pool_s。
typedef struct ngx_pool_s ngx_pool_t;


//  \nginx-1.27.4\src\core\ngx_palloc.h
struct ngx_pool_s {
    ngx_pool_data_t       d;         	// 当前内存池的数据区，用于存储小块内存。 这是一个嵌套的结构体，它包含了内存池中实际的数据存储区域以及一些管理信息。
    size_t                max;       	// 小块内存的最大大小，超过此大小的内存会被视为“大块内存”，单独分配。
    ngx_pool_t           *current;  	// ngx_pool_t是指向自身结构体的指针。当前内存池链表节点，指向当前内存池链表节点。如果当前内存池用尽，会创建一个新的内存池节点并链接到链表中。
    ngx_chain_t          *chain;    	// 链表，
    ngx_pool_large_t     *large;    	// 大块内存链表，用于管理大块内存（超过 max 的内存）。
    ngx_pool_cleanup_t   *cleanup;  	// 清理回调函数链表
    ngx_log_t            *log;      	// 日志对象，用于记录内存分配和释放的相关信息。
};

```



在处理每个 TCP/HTTP 请求时，Nginx 会为该请求创建一个独立的内存池。

```c
ngx_pool_t *pool = ngx_create_pool(1024, log);                   // 1024 ：表示初始分配的内存大小（以字节为单位）。
if (pool == NULL) {
    ngx_log_error(NGX_LOG_ERR, log, 0, "Failed to create pool");
}
```





Nginx 的代码风格非常注重一致性和可读性。为了便于维护和理解代码，Nginx 使用了一套统一的命名规则：

- **`_s` 后缀** ：表示结构体的内部名称（`struct` 定义部分）。
- **`_t` 后缀** ：表示类型别名（`typedef` 定义的部分），通常用于简化代码中的类型使用。
- `ngx_pool_s`：是结构体的内部名称，表示这是一个具体的结构体定义。
- `ngx_pool_t`：是类型别名，表示这是一个简化的类型名称，方便在代码中使用。



### 内存操作函数







## Nginx请求处理11个阶段



Nginx HTTP 请求处理的 11 个阶段。Nginx 的 HTTP 请求处理流程被划分为多个阶段，每个阶段都有特定的任务，并且允许模块介入并处理请求。理解这些阶段对于开发 Nginx 模块至关重要。

以下是 Nginx HTTP 请求处理的 11 个标准阶段（在 Nginx 1.x 版本之后引入了更多的细分，但通常我们讨论的是这 11 个核心阶段）：



1. **`NGX_HTTP_POST_READ_PHASE` (读取请求体之后阶段):**
   - 在这个阶段，Nginx 已经读取了客户端的请求头，并且如果配置了读取请求体（例如，对于 POST 请求），也已经读取了部分或全部请求体。
   - 模块可以在这个阶段检查请求的完整性、进行初步的请求体处理等。
2. **`NGX_HTTP_SERVER_REWRITE_PHASE` (服务器重写阶段):**
   - 这个阶段主要处理基于服务器级别的重写规则。
   - 模块（如 `ngx_http_rewrite_module`）可以在这里修改请求的 URI、进行重定向等操作。
3. **`NGX_HTTP_FIND_CONFIG_PHASE` (查找配置阶段):**
   - 在这个阶段，Nginx 根据请求的主机名（Host 头）和 URI 查找匹配的虚拟主机（`server` 块）和 location 块。
   - 这个阶段的结果决定了后续哪些配置块将被用于处理该请求。
4. **`NGX_HTTP_REWRITE_PHASE` (位置重写阶段):**
   - 这个阶段处理在匹配的 `location` 块中定义的重写规则。
   - 与服务器重写阶段类似，模块可以在这里修改请求的 URI、进行重定向等操作，但作用范围是当前的 `location` 块。
5. **`NGX_HTTP_POST_REWRITE_PHASE` (重写提交后阶段):**
   - 在重写阶段（服务器或位置）执行完毕后，如果 URI 被修改，Nginx 会跳转回查找配置阶段（`NGX_HTTP_FIND_CONFIG_PHASE`）重新查找匹配的 `location`。这个阶段允许模块在重写完成后执行一些操作。
6. **`NGX_HTTP_PREACCESS_PHASE` (预访问阶段):**
   - 这个阶段在访问控制之前执行。
   - 模块可以在这里进行一些全局性的访问控制预处理，例如限制并发连接数、IP 黑名单检查等。
7. **`NGX_HTTP_ACCESS_PHASE` (访问控制阶段):**
   - 这个阶段执行访问控制相关的模块，例如 `ngx_http_access_module`（基于 IP 地址的访问控制）、`ngx_http_auth_basic_module`（基本认证）等。
   - 如果访问被拒绝，Nginx 会返回相应的 HTTP 错误码（例如 403 Forbidden）。
8. **`NGX_HTTP_POST_ACCESS_PHASE` (访问控制后阶段):**
   - 在访问控制阶段之后执行，允许模块在访问控制决策之后执行一些操作，例如记录访问日志。
9. **`NGX_HTTP_PRECONTENT_PHASE` (预内容处理阶段):**
   - 这个阶段在生成实际内容之前执行。
   - 模块可以在这里进行一些内容处理的准备工作，例如检查缓存、处理 FastCGI 或 uWSGI 的 upstream 连接等。
10. **`NGX_HTTP_CONTENT_PHASE` (内容生成阶段):**
    - 这是最核心的阶段，负责生成 HTTP 响应的内容。
    - 处理静态文件的模块（如 `ngx_http_static_module`）、代理模块（如 `ngx_http_proxy_module`）、FastCGI 模块（如 `ngx_http_fastcgi_module`）以及您自定义的模块通常在这个阶段工作。
    - 一个请求只能由一个内容处理器来处理。
11. **`NGX_HTTP_LOG_PHASE` (日志记录阶段):**
    - 这是请求处理的最后一个阶段。
    - `ngx_http_log_module` 等模块在这个阶段记录请求的详细信息到日志文件中。



Nginx 的请求处理流程是一个管道，请求会依次通过这些阶段。每个阶段都有机会被一个或多个模块处理。模块可以通过注册自己的处理函数到特定的阶段来介入请求处理流程，实现各种功能，例如修改请求、进行认证授权、生成动态内容、记录日志等。

理解这些阶段对于 Nginx 的配置和模块开发至关重要，因为它决定了模块在何时以及如何影响请求的处理过程。



**从概念上讲，Nginx 的“阶段 (Phase)” 是指在处理一个 HTTP 请求的过程中，Nginx 定义的不同处理环节或步骤。** 

就像一条装配线上的不同工位，每个阶段负责执行特定的任务。这种分阶段的设计使得 Nginx 的架构非常模块化和可扩展。不同的模块可以注册到不同的阶段，以便在请求处理的不同环节介入并执行它们特定的逻辑



Nginx 在其头文件（通常是 `ngx_http_core_module.h`）中定义了一系列整数常量，用来标识不同的 HTTP 请求处理阶段。这些常量通常是枚举类型或者简单的 `define` 宏，它们的值是唯一的，用于在 Nginx 核心和各个 HTTP 模块之间进行识别和引用。

```c
//在 C 语言的枚举类型（enum）中，如果您只为第一个枚举成员显式地赋值，那么后续的枚举成员将默认地按照它们在定义中的顺序，从前一个成员的值开始，依次递增 1。
typedef enum {
    NGX_HTTP_POST_READ_PHASE = 0,

    NGX_HTTP_SERVER_REWRITE_PHASE,

    NGX_HTTP_FIND_CONFIG_PHASE,
    NGX_HTTP_REWRITE_PHASE,
    NGX_HTTP_POST_REWRITE_PHASE,

    NGX_HTTP_PREACCESS_PHASE,

    NGX_HTTP_ACCESS_PHASE,
    NGX_HTTP_POST_ACCESS_PHASE,

    NGX_HTTP_PRECONTENT_PHASE,

    NGX_HTTP_CONTENT_PHASE,

    NGX_HTTP_LOG_PHASE
} ngx_http_phases;
```





```c
// ngx_http_core_module.h


typedef struct ngx_http_phase_handler_s  ngx_http_phase_handler_t;


// 在 C 语言中，函数指针是一种特殊的指针变量，它存储的是函数的内存地址。通过函数指针，我们可以像调用普通函数一样调用它所指向的函数。这为实现回调函数、动态调度等高级编程技巧提供了基础。


// typedef 关键字用于为现有的数据类型创建一个新的别名。在这里，我们要为一种特定的函数指针类型创建一个别名 ngx_http_phase_handler_pt 

// ngx_int_t: 这是函数指针所指向的函数的返回类型。ngx_int_t 是 Nginx 中常用的表示整型返回值的类型，通常用于指示操作的成功与否（例如 NGX_OK 表示成功，NGX_ERROR 表示失败，以及其他特定的状态码）。

// (*ngx_http_phase_handler_pt): 这一部分定义了我们要创建的函数指针类型的名称。
		// * 表明这是一个指针类型
		// ngx_http_phase_handler_pt 是我们为这个函数指针类型取的别名。
		// 括号 () 包裹着 *ngx_http_phase_handler_pt，这在声明函数指针类型时是必需的，以区分它和返回指针的函数。

// (ngx_http_request_t *r, ngx_http_phase_handler_t *ph): 这部分定义了函数指针所指向的函数的参数列表：
		// ngx_http_request_t *r: 这是指向 ngx_http_request_t 结构体的指针。ngx_http_request_t 是 Nginx 中最核心的数据结构之一，它包含了与当前正在处理的 HTTP 请求相关的所有信息。这包括客户端连接信息、请求行（方法、URI、协议）、请求头、请求体、以及用于存储模块数据的各种字段。通过这个指针，函数可以访问和操作当前请求的各种属性。
		//ngx_http_phase_handler_t 是 struct ngx_http_phase_handler_s 的别名，它代表着当前 HTTP 处理阶段中的一个具体的处理步骤。通过这个指针，函数可以访问到与当前处理步骤相关的上下文信息，例如可能包含一些配置数据或者状态信息。
typedef ngx_int_t (*ngx_http_phase_handler_pt)(ngx_http_request_t *r, ngx_http_phase_handler_t *ph);



// struct ngx_http_phase_handler_s 结构体正是 Nginx HTTP 请求处理流程中，在每个处理阶段（如读取请求头后、服务器重写、查找配置、位置重写、访问控制、内容生成、日志记录等）中执行的单个处理步骤的抽象表示。

// 每个 ngx_http_phase_handler_s 实例都代表着一个需要在特定阶段执行的“动作”或“处理逻辑”。
// 1. checker: 允许 Nginx 在执行真正的 handler 之前，先调用一个检查函数（checker 字段是一个函数指针，它的类型是 ngx_http_phase_handler_pt）来判断是否需要执行当前的 handler。这提供了一种条件执行处理逻辑的机制。
// 2. handler: 指向实际执行该处理步骤的函数。这个函数包含了该步骤的核心业务逻辑。
// 3. next: 用于将多个 ngx_http_phase_handler_s 结构体链接在一起，形成一个处理链。在一个 HTTP 处理阶段中，可能会注册多个处理函数，它们会按照 next 指示的顺序依次执行。

//因此，可以将 ngx_http_phase_handler_s 看作是构成 Nginx HTTP 请求处理管道中每个阶段的基本构建块。通过组合和链接这些处理句柄，Nginx 可以灵活地处理各种 HTTP 请求。

struct ngx_http_phase_handler_s {
    ngx_http_phase_handler_pt  checker;
    ngx_http_handler_pt        handler;
    ngx_uint_t                 next;
};



// 总而言之，这三个类型定义和结构体定义共同描述了 Nginx HTTP 请求处理管道中每个阶段的处理步骤：

// 1. ngx_http_phase_handler_t 是对一个处理步骤结构体的统一称呼。
// 2. ngx_http_phase_handler_pt 定义了用于条件检查处理步骤是否需要执行的函数的类型。
// 3. ngx_http_handler_pt 定义了实际执行处理逻辑的函数的类型.

// ngx_http_phase_handler_s 结构体本身包含了执行条件检查的函数指针 (checker)、执行实际处理的函数指针 (handler)，以及指向下一个处理步骤的索引 (next)，从而构成了一个可链接的处理单元。

// 通过这种设计，Nginx 可以在每个 HTTP 请求处理阶段注册多个模块提供的处理函数，并灵活地控制它们的执行顺序和条件。
```





## 开发第一个模块



```c
#include <ngx_config.h>
#include <ngx_core.h>
#include <ngx_http.h>

// 模块配置结构体:依据Nginx命名规范，结构体的名字是ngx_http_ndg_hello_loc_conf_t，其中ngx_http表示是HTTP模块，ndg_hello是模块名字，loc_conf表示存储location的配置。
// 结构体 
typedef struct {
    ngx_str_t   output_string;
} ngx_http_ndg_hello_loc_conf_t;

// 模块上下文结构体
static ngx_http_module_t  ngx_http_ndg_hello_module_ctx = {
    NULL,                          /* preconfiguration */
    ngx_http_ndg_hello_init,      /* postconfiguration */

    NULL,                          /* create main configuration */
    NULL,                          /* init main configuration */

    NULL,                          /* create server configuration */
    NULL,                          /* merge server configuration */

    ngx_http_ndg_hello_create_loc_conf, /* create location configuration */
    ngx_http_ndg_hello_merge_loc_conf    /* merge location configuration */
};

// 模块定义
ngx_module_t  ngx_http_ndg_hello_module = {
    NGX_MODULE_V1,
    &ngx_http_ndg_hello_module_ctx, /* module context */
    ngx_http_ndg_hello_commands,    /* module directives */
    NGX_HTTP_MODULE,               /* module type */
    NULL,                          /* init master */
    NULL,                          /* init module */
    NULL,                          /* init process */
    NULL,                          /* init thread */
    NULL,                          /* exit thread */
    NULL,                          /* exit process */
    NULL,                          /* exit master */
    NGX_MODULE_V1_PADDING
};

// 模块指令
static ngx_command_t  ngx_http_ndg_hello_commands[] = {

    { ngx_string("ndg_hello_output"),
      NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
      ngx_conf_set_str_slot,
      NGX_HTTP_LOC_CONF_OFFSET,
      offsetof(ngx_http_ndg_hello_loc_conf_t, output_string),
      NULL },

    ngx_null_command
};

// 创建 location 配置结构体
static void *
ngx_http_ndg_hello_create_loc_conf(ngx_conf_t *cf)
{
    ngx_http_ndg_hello_loc_conf_t  *conf;

    conf = ngx_pcalloc(cf->pool, sizeof(ngx_http_ndg_hello_loc_conf_t));
    if (conf == NULL) {
        return NULL;
    }

    // 设置默认输出字符串
    ngx_str_set(&conf->output_string, "Hello from NDG!");

    return conf;
}

// 合并 location 配置结构体
static char *
ngx_http_ndg_hello_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child)
{
    ngx_http_ndg_hello_loc_conf_t *prev = parent;
    ngx_http_ndg_hello_loc_conf_t *conf = child;

    ngx_conf_merge_str_value(cf, &conf->output_string, &prev->output_string);

    return NGX_CONF_OK;
}

// 处理请求的 handler 函数
static ngx_int_t
ngx_http_ndg_hello_handler(ngx_http_request_t *r)
{
    ngx_buf_t             *b;
    ngx_chain_t           out;
    ngx_http_ndg_hello_loc_conf_t  *conf;

    // 获取当前 location 的配置
    conf = ngx_http_get_module_loc_conf(r, ngx_http_ndg_hello_module);

    // 设置响应类型为 text/plain
    r->headers_out.content_type.len = sizeof("text/plain") - 1;
    r->headers_out.content_type.data = (u_char *) "text/plain";

    // 分配缓冲区
    b = ngx_pcalloc(r->pool, sizeof(ngx_buf_t));
    if (b == NULL) {
        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Failed to allocate response buffer");
        return NGX_HTTP_INTERNAL_SERVER_ERROR;
    }

    // 将输出字符串复制到缓冲区
    b->pos = conf->output_string.data;
    b->last = conf->output_string.data + conf->output_string.len;
    b->memory = 1;    /* this buffer is in memory */
    b->last_buf = (r == r->main) ? 1 : 0; /* set the "last" flag if this is the last buffer */

    // 创建缓冲区链
    out.buf = b;
    out.next = NULL;

    // 发送 HTTP 头
    r->headers_out.status = NGX_HTTP_OK;
    ngx_http_send_header(r);

    // 发送响应体
    return ngx_http_output_filter(r, &out);
}

// 模块初始化函数
static ngx_int_t
ngx_http_ndg_hello_init(ngx_conf_t *cf)
{
    ngx_http_handler_pt        *h;
    ngx_http_core_main_conf_t  *cmcf;

    cmcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_core_module);

    // 在 content 阶段注册我们的 handler
    h = ngx_array_push(&cmcf->phases[NGX_HTTP_CONTENT_PHASE].handlers);
    if (h == NULL) {
        return NGX_ERROR;
    }

    *h = ngx_http_ndg_hello_handler;

    return NGX_OK;
}
```



