

# 背景

在互联网公司中，做为 OLTP 的数据库系统，分库分表一定是为了 **支撑高并发、数据量大** 两个问题的。





https://qiuyadongsite.github.io/2020/02/19/how-problems-24/







假如我们现在是一个小创业公司（或者是一个 BAT 公司刚兴起的一个新部门），现在注册用户就 20 万，每天活跃用户就 1 万，每天单表数据量就 1000，然后高峰期每秒钟并发请求最多就 10 个。

就这种系统，随便找一个有几年工作经验的，然后带几个刚培训出来的，随便干干都可以。



结果没想到我们运气居然这么好，碰上个 CEO 带着我们走上了康庄大道，业务发展迅猛，过了几个月，注册用户数达到了 2000 万！每天活跃用户数 100 万！

每天单表数据量 10 万条！高峰期每秒最大请求达到 1000！同时公司还顺带着融资了两轮，进账了几个亿人民币啊！公司估值达到了惊人的几亿美金！这是小独角兽的节奏！

好吧，没事，现在大家感觉压力已经有点大了，为啥呢？因为每天多 10 万条数据，一个月就多 300 万条数据，现在咱们单表已经几百万数据了，马上就破千万了。但是勉强还能撑着。高峰期请求现在是 1000，咱们线上部署了几台机器，负载均衡搞了一下，数据库撑 1000QPS 也还凑合。

但是大家现在开始感觉有点担心了，接下来咋整呢......

再接下来几个月，我的天，CEO 太牛逼了，公司用户数已经达到 1 亿，公司继续融资几十亿人民币啊！公司估值达到了惊人的几十亿美金，成为了国内今年最牛逼的明星创业公司！天，我们太幸运了。

但是我们同时也是不幸的，因为此时每天活跃用户数上千万，每天单表新增数据多达 50 万，目前一个表总数据量都已经达到了两三千万了！扛不住啊！数据库磁盘容量不断消耗掉！高峰期并发达到惊人的 `5000~8000` ！别开玩笑了，哥。我跟你保证，你的系统支撑不到现在，已经挂掉了！

好吧，所以你看到这里差不多就理解分库分表是怎么回事儿了，实际上这是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。







# 分表



比如你单表都几千万数据了，你确定你能扛住么？绝对不行，**单表数据量太大**，会极大影响你的 sql **执行的性能**，到了后面你的 sql 可能就跑的很慢了。

一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。

分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。

比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。

这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。

这种



### 分区表

在日常的工作中，我们经常遇到一张表里面保存了上亿甚至过十亿的记录。这些表里面保存了大量的历史记录。（比如一些日志表，归档表）

对于那些已经失去保存意义的数据，通常可以通过删除与那些数据有关的分区，很容易地删除那些数据。

比如一些订单表，流水表，日志表，一些网站经常是只支持近两三年的归档数据查询，更早期的数据，无法被查到。

这种情况就是删除了老分区的数据。或者冷备份归档。



相反地，在某些情况下，添加新数据的过程又可以通过为那些新数据专门增加一个新的分区，来很方便地实现。比如订单表，日志表 ，按年按月分区。



对于这些历史数据的清理是一个非常头疼事情，由于所有的数据都一个普通的表里。

所以只能是启用一个或多个带 where 条件的 delete 语句去删除（一般where条件是时间）。

> **淘宝万亿级交易订单背后的存储引擎**
>
> https://tech.antfin.com/docs/2/161461
>

面对这类问题，最有效的方法就是在使用 **MySQL分区表**。



**分区表在逻辑上表现为一个表，在物理上存储在多个文件中。**。

**注意，分区表是在单个实例上进行的分区。实际上对性能的提升是有限的。**



每个文件是一个分区。

- RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区。 
  - 根据分区键值的范围把数据行存储到表的不同分区中
  - 最常见的是基于时间字段。基于分区的列最好是整型，如果日期型的可以使用函数转换为整型。
  - 多个分区的范围要连续，但是不能重叠。
  - 默认情况下使用 VALUES LESS THAN 属性，即每个分区不包括指定的那个值。
  - 适用场景：
- LIST分区：类似于按RANGE分区，区别在于 LIST 分区是基于列值匹配一个离散值集合中的某个值来进行选择。 
- HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。
- KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL 服务器提供其自身的哈希函数。必须有一列或多列包含整数值。



#### range分区

```sql
-- 基于时间的 range 范围分区
-- TO_DAYS(hiredate) 按日期分区
-- YEAR(purchased) 按年分区  
CREATE TABLE my_range_datetime(
    id INT,
    hiredate DATETIME not null 
) 
PARTITION BY RANGE (TO_DAYS(hiredate) ) (
    PARTITION p1 VALUES LESS THAN ( TO_DAYS('20171202') ),
    PARTITION p2 VALUES LESS THAN ( TO_DAYS('20171203') ),
    PARTITION p3 VALUES LESS THAN ( TO_DAYS('20171204') ),
    PARTITION p4 VALUES LESS THAN ( TO_DAYS('20171205') ),
    PARTITION p5 VALUES LESS THAN ( TO_DAYS('20171206') ),
    PARTITION p6 VALUES LESS THAN ( TO_DAYS('20171207') ),
    PARTITION p7 VALUES LESS THAN ( TO_DAYS('20171208') ),
    PARTITION p8 VALUES LESS THAN ( TO_DAYS('20171209') ),
    PARTITION p9 VALUES LESS THAN ( TO_DAYS('20171210') ),
    PARTITION p10 VALUES LESS THAN ( TO_DAYS('20171211') ),
    PARTITION p11 VALUES LESS THAN (MAXVALUE) 
);

-- p11是一个默认分区，所有大于20171211的记录都会在这个分区。MAXVALUE是一个无穷大的值。p11是一个可选分区。
-- 如果在定义表的没有指定的这个分区，当我们插入大于20171211的数据的时候，会收到一个错误。




-- 员工分区表

-- p0分区: id为0-5的员工
-- p1分区: id为6-10的员工
-- p2分区: id为11-15的员工
-- p3分区: id为16-20的员工

CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT NOT NULL,
    store_id INT NOT NULL
)
PARTITION BY RANGE (store_id) (
    PARTITION p0 VALUES LESS THAN (6),
    PARTITION p1 VALUES LESS THAN (11),
    PARTITION p2 VALUES LESS THAN (16),
    PARTITION p3 VALUES LESS THAN (21)
);
```





#### HASH分区

- 根据 MOD(分区键，分区数) 的值把数据行存储到表的不同分区中
- 数据可以平均的分布在各个分区中，分片是偏随机的。（因为是哈希分区）
- **HASH 分区的键值必须是一个INT类型的值，或是通过函数可以转为INT类型**
- **对于非整形的HASH往表插入数据的过程中会多一步表达式的函数计算操作，所以不建议使用复杂的表达式这样会影响性能。**



```sql
-- 比如用户登陆日志表

CREATE TABLE `customer_login_log` (
  `customer_id` int(10) unsigned NOT NULL COMMENT '登录用户ID',
  `login_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '用户登录时间',
  `login_ip` int(10) unsigned NOT NULL COMMENT '登录IP',
  `login_type` tinyint(4) NOT NULL COMMENT '登录类型:0未成功 1成功'
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='用户登录日志表'

PARTITION BY HASH(customer_id)  PARTITIONS 4;



-- 如果不分区，表文件表现为：
customer_login_log.frm    -- 存储表原数据信息
customer_login_log.ibd    -- InnoDB数据文件

-- hash分区后的文件
customer_login_log.frm    
customer_login_log#P#p0.ibd
customer_login_log#P#p1.ibd
customer_login_log#P#p2.ibd
customer_login_log#P#p3.ibd


-- 使用起来和不分区是一样的，看起来只有一个数据库，其实有多个分区文件，比如我们要插入一条数据，不需要指定分区，MySQL会自动帮我们处理
```





### LIST分区

list分区其实很像hash分区，在 range 分区中，每个分区键必须显式定义，分区键是连续区间。

list 分区，分区键是一个 list 。或者说枚举类型。



-  list 分区，被分区的列必须是 not null 。否则插入null 值如果枚举列表里面不存在 null 值会插入失败，
- list 分区只支持整型，非整形字段需要通过函数转换成整型。

```sql
-- 员工表

-- 单表情况下，会在数据目录生成一个employees.ibd文件来存放数据
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT,
    store_id INT
);


-- list分区，将员工按照id分区，分为：

-- 北区: id为(3,5,6,9,17)
-- 东区：id为(1,2,10,11,19,20)
-- 西区: id为(4,12,13,14,18)
-- 中区: id为(3,5,6,9,17)

-- 分区表情况下，会在数据目录生成一个各个分区的ibd文件来存放数据
CREATE TABLE employees_part (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT,
    store_id INT
)
-- 分区键可以直接是列，或者作用在列上的表达式，只要返回类型是int
PARTITION BY LIST(store_id) (
    PARTITION pNorth VALUES IN (3,5,6,9,17),
    PARTITION pEast VALUES IN (1,2,10,11,19,20),
    PARTITION pWest VALUES IN (4,12,13,14,18),
    PARTITION pCentral VALUES IN (7,8,15,16)
);
```







### 物理分表

就是把一个表的数据放到多个物理表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。

然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。







# 数据库分片（分库）



## 水平拆分



**水平拆分**的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样。

只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。

水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。









## 垂直拆分



### 垂直分库



比如新闻网站中，注册用户的信息与新闻数据是没有多大关系的。

数据库访问压力大时可以尝试把用户注册信息的表放在一个数据库，新闻相关的表放在另一个数据库中，这样减小了数据库的访问压力，同时便于对每个单独的业务按需进行水平扩展。

这就与微服务的思想逐渐靠近，但具体业务拆分如何拆分，怎么控制拆分粒度，这需要根据业务进行仔细考量了。因为垂直分库会带来以下几个问题：



- **事务的ACID将被打破**：数据被分到不同的数据库，原来的事务操作将会受很大影响。

  比如说注册用户时需要在一个事务中往用户表和用户信息表插入一条数据，单机数据库可以利用本地事务很好地完成这件事儿，但是多机就会变得比较麻烦。这个问题就涉及到分布式事务，分布式事务的解决方案有很多，比如使用强一致性的分布式事务框架Seata，或者使用RocketMQ等消息队列实现最终一致性。

- **Join联表操作困难**：这个也毋庸置疑了，解决方案一般是将联表查询改成多个单次查询，在代码层进行关联。
- **外键约束受影响**：因为外键约束和唯一性约束一样本质还是依靠索引实现的，所以分库后外键约束也会收到影响。但外键约束本就不太推荐使用，一般都是在代码层进行约束，这个问题倒也不会有很大影响。



### 垂直分表

垂直分表的方式：**主要以字段为依据，按照字段的活跃度，将表中的字段拆分到不同的表中**。



将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表。

非热点数据放在一起作为扩展表。

这样主表的单行数据所需的存储空间变小，更多的热点数据就能被缓存下来，进而减少了随机磁盘I/O。

拆了之后，要想获得全部数据就需要关联两个表来取数据。



比如用户表数据，用户的用户名、密码、年龄、性别、手机号等字段会被经常查询，而用户的家庭住址、个人介绍等字段又长而且不常访问，所以将这些字段拆分出来单独存一张表，可以让数据库的缓存更高效。



## 数据库中间件



# 分库分表面试题





为什么要分库分表（设计高并发系统的时候，数据库层面该如何设计）？

用过哪些分库分表中间件？

不同的分库分表中间件都有什么优点和缺点？

你们具体是如何对数据库如何进行垂直拆分或水平拆分的？











## 面试官心理分析



其实这块肯定是扯到**高并发**了，因为分库分表一定是为了**支撑高并发、数据量大**两个问题的。

而且现在说实话，尤其是互联网类的公司面试，基本上都会来这么一下，分库分表如此普遍的技术问题，不问实在是不行，而如果你不知道那也实在是说不过去！