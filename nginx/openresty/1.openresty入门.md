# OpenResty简介 



> `OpenResty®` 是一个基于 Nginx 与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。
>
> 用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。



OpenResty 基于`Nginx`开发，可以简单认为是 `Nginx` + `lua-nginx-module`的组合版。

- [官网](https://openresty.org/cn/)
- [官方文档](https://github.com/openresty/lua-nginx-module#version)

高性能服务端两个重要要素：

- 需要支持缓存：缓存速度上，内存 > SSD > 机械磁盘；本机 > 网络 ； 进程内 > 进程间 。
- 语言层面要支持异步非阻塞：异步非阻塞指的是事件驱动方式（事件完成后再通知）。



OpenResty 包含的技术：

- Nginx：不仅仅是负载均衡+反向代理等功能，Nginx c module开发成本高。
- LuaJIT：OpenResty用的是 LuaJIT，LuaJIT 是主打性能的Lua。

`OpenResty` 本质上是将 `LuaJIT` 的虚拟机嵌入到 Nginx的worker中，所以效率特别高，在性能上，`OpenResty` 接近或超过 Nginx c module









# API 网关



### 什么是 API 网关



![img](assets/d76d1acfeb3a02db533a9061eeda4d34)



以 Kong 为例，左图没有 API 网关，但是后面挂了很多服务，如果每个服务都要实现包括认证、统计、安全校验等功能，会有很多重复的工作。



API 网关的作用就是把这些公共的东西抽取出来，如右图，下面的这几个服务，每个服务都只关心自身业务相关的东西，和业务无关的东西全部都丢到API 网关上。

即 API 网关就是把公共的东西如统计、安全、限流、限速、缓存等提取出来做了一个中间层。



### API 网关的传统功能

- 让 API 请求更安全、更高效的得到处理。传统的 API 网关有一些基本的功能直到现在都适用的，管理不管南北向的还是东西向的 API   流量可以能够快速、安全地得到处理，这个是 API 网关始的目的。

- 覆盖 Nginx 的所有功能。API 的网关覆盖了 Nginx 的所有功能，包括反向代理、负载均衡以及基本的缓存、安全的认证、限流限速等。
- 支持 Nginx 等 Web 服务器实现不了的功能。如动态上游、动态 SSL 证书、动态限流限速，以及主动/被动健康检查、服务熔断等，这些动态的能力都是传统的 Nginx、Apache 这类Web 服务器支持不了的。
- 全生命周期管理。在 API 网关领域，大玩家是谷歌，谷歌在 2016 年收购了一家上市公司 Apigee，它现在把整个功能集成在谷歌云上。A
  - PI 网关除了我们熟悉的反向代理、负载均衡、限流限速的插件外，它还包括了 API   的设计、文档以及测试等，这一整套都属于 API 网关的功能，我们叫做 API 的全生命周期管理。
  - 从项目设计到测试上线，所有的东西都在整个 API 网关的功能范畴内。

### 云原生下的新功能

为什么现在包括 Kong、Apache APISIX 还要把传统的东西再做一遍呢？这是因为在云原生和微服务体系下，用户和技术架构有了一些新的变化：

- 需要对接云原生里面像 Prometheus、Zipkin、Skywalking 等重要组件；
- gRPC 代理和协议转换（REST<=>gRPC）：HTTP 这种协议在微服务里面用的越来越少，很多人开始用 gRPC，那在从 HTTP 到 gRPC 协议的转换，这种功能也是需要的，包括 gRPC 的代理；
- 身份认证方式改变：在传统的 Nginx 里面，一般是流量进来后根据路由的规则去做反向代理、负载均衡，很少对发流量的客户端的身份做认证。
  - 但是在云原生里面就不一样，因为很多是在微服务里的流量，这里面需要做严格的身份认证，包括加密、OpenID 之类的身份认证。
  - 这块就是一些新的功能，可以把自己企业里面需要做身份认证相关的东西放到第三方的外部认证的厂商去做。
- Serverless 也是近几年非常火的一个概念，比如希望在边缘节点上面动态地把一个函数跑起来或者把一个函数给停掉，或者动态地去改里面的内容。
  - 你可以把你的 API 网关部署在边缘节点上，具备了这种 FaaS 的功能，你的边缘节点就会更加地灵活。
  - Apache APISIX 里面就支持了 Serverless，可以让你的一个 Lua 的函数动态地在边缘结点跑起来；
- 无状态、随意扩容和缩容：API 网关在十多年前性能要求没有那么高，因为当时互联网的流量更多地是从浏览器到服务端，没有手机和物联网的设备，也没有微服务、内网这些流量。
  - 但是现在的流量很大，包括   4G、5G下面有很多的手机、IoT 设备去访问服务端，流量特别地大。此时，就需要一个性能更高的 API 网关去做支撑。
  - 云原生的一个重要的标准是所有的服务都可以通过容器的方式随意地去扩容和缩容，对 Kubernetes 友好；
- 支持多云和混合云：现在上云已经是一个趋势，但是我们一般不太会把服务只放在一个云上，比如腾讯云、谷歌云、阿里云各放一部分，私有云再放一部分。
  - 根据它们的安全和价格做调整，私有的一些数据安全性更高的放在私有云上，资源比如和 CDN 相关的哪个便宜就放哪个云上，做动态的切换，那么此时就需要有一个和厂商无关的 API 网关放在前面做分发。
- 





在Service Mesh微服务架构中，我们常常会听到东西流量和南北流量两个术语。

南北流量（NORTH-SOUTH traffic）和东西流量（EAST-WEST traffic）是数据中心环境中的网络流量模式。下面我们通过一个例子来理解这两个术语。

假设我们尝试通过浏览器访问某些Web应用。Web应用部署在位于某个数据中心的应用服务器中。

在多层体系结构中，典型的数据中心不仅包含应用服务器，还包含其他服务器，如负载均衡器、数据库等，以及路由器和交换机等网络组件。假设应用服务器是负载均衡器的前端。

当我们访问web应用时，会发生以下类型的网络流量：

- 客户端（位于数据中心一侧的浏览器）与负载均衡器（位于数据中心）之间的网络流量。

  - 南北流量：在这个例子中，前者即即客户端和服务器之间的流量被称为南北流量。简而言之，南北流量是server-client流量。

- 负载均衡器、应用服务器、数据库等之间的网络流量，它们都位于数据中心。

  - 第二种流量即不同服务器之间的流量与数据中心或不同数据中心之间的网络流被称为东西流量。简而言之，东西流量是server-server流量。

  

  当下，东西流量远超南北流量，尤其是在当今的大数据生态系统中，比如Hadoop生态系统（大量server驻留在数据中心中，用map reduce处理），server-server流量远大于server-client流量。

  

  大家可能会好奇，东西南北，为什么这么命名。

  该命名来自于绘制典型network diagrams的习惯。在图表中，通常核心网络组件绘制在顶部（NORTH），客户端绘制在底部（SOUTH），而数据中心内的不同服务器水平（EAST-WEST）绘制。

  

  



# Apache APISIX

> **Apache APISIX** is a dynamic, real-time, high-performance API gateway.
>
> APISIX provides rich traffic management features such as load balancing, dynamic upstream, canary release, circuit breaking, authentication, observability, and more.

