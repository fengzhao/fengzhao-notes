# HDFS架构

HDFS是一种可以运行在廉价的服务器上的文件系统，具有高度容错的特性。它可以提供对大规模数据集的高吞吐量的访问，适用于基于大量数据的应用。

HDFS最初是Apache Nutch（web搜索引擎项目）的基础架构，现在已经成为Apache Hadoop核心项目的一部分。

## HDFS构想和目标


**硬件故障**

一个hdfs文件系统实例可能有成百上千个服务器构成，每个服务器存储文件系统的一部分数据。事实上，硬件故障是常态，构成hdfs的服务器组件发生故障是大概率事件，这也意味着总有部分服务器因为故障而变得不可用。因此，故障的探测以及从这些故障中自动、快速的恢复是hdfs架构设计的一个核心目标。


**流数据访问**

运行在HDFS上的应用和普通的应用不同，需要流式访问它们的数据集。HDFS的设计中更多的考虑到了数据批处理，而不是用户交互处理。比之数据访问的低延迟问题，更关键的在于数据访问的高吞吐量。POSIX标准设置的很多硬性约束对HDFS应用系统不是必需的。为了提高数据的吞吐量，在一些关键方面对POSIX的语义做了一些修改。



**大规模数据集**

hdfs上的一个文件的大小可能是GB到TB级别，hdfs需要优化大文件的存储。它应该提供高聚合的数据带宽并扩展到单个集群中的数百个节点。一个hdfs实例中应该支持成千上万个文件的存储。

**简单的一致性模型**

hdfs应用需要一个对文件“一次写入多次读取”的访问模型。一个文件一旦创建、写入、关闭后就不应该再被修改，除了追加append操作和情况truncate操作。hdfs应该支持对文件的追加而不支持对任意位置的修改。这种设想简化了数据的一致性问题并且能极大提高数据访问的吞吐量，并完美适用于MapReduce和网络爬虫应用。

**移动计算成本远小于移动数据**

计算操作如果距离操作的数据近（网络上的距离，最理想的就是在一台机器上）的话效率往往更高，尤其是在大规模数据集的情况下。这种移动计算的设想最小化了网络阻塞，增加了系统的整体吞吐量（不需要传输大量数据到应用所在的节点上）。hdfs提供了接口来将应用程序分配到数据所在的节点上。

**跨硬件和软件平台的可移植性**

hdfs被设计为可以容易的从一个平台移植到另一个平台，这种特性有助于hdfs被广泛采用为作为大规模应用的基础平台。

**NameNode和DataNodes**

hdfs采用主从架构，由一个NameNode节点和多个DataNode节点构成，其中NameNode所在的服务器（主）起到管理hdfs的命名空间和限制客户端对文件访问的作用。
而DataNode则主要负责其所在服务器的数据的存储，通常情况下，集群中的每个服务器都有一个DataNode进程（一个服务器上有多个DataNode进程也可以，但不常见）。DataNode提供了对文件数据的存储，更底层的说，是以block的形式来存储数据的。一个文件会被拆分为多个block存储在多个DataNode中。NameNode执行对元数据的操作如打开、关闭、重命名文件和目录等，它还决定了block到DataNode的映射。DataNode则负责接收客户端的读写请求，并在NameNode的指导下对block进行创建、删除、复制操作。